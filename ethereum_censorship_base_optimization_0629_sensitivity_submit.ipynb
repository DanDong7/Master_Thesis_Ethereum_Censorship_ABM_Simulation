{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "import logging\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle as pkl\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pytest\n",
    "import time\n",
    "import networkx as nx\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import json\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory (standardized location)\n",
    "base_result_folder = os.path.join(os.getcwd(), \"simulation_results_SA_0608\")\n",
    "timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "main_experiment_folder = f\"sensitivity_builder_review_time_per_tx_{timestamp_str}\"\n",
    "main_result_folder = os.path.join(base_result_folder, main_experiment_folder)\n",
    "os.makedirs(main_result_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# # Default log path (commented out to disable file logging)\n",
    "# default_log_filename = os.path.join(main_result_folder, 'default_simulation.log')\n",
    "\n",
    "# Configure logging (file logging + console output)\n",
    "# Logging to file is disabled here to avoid inconsistencies in multi-threaded or multi-process execution\n",
    "logging.basicConfig(\n",
    "    level=logging.CRITICAL,   # Other levels include DEBUG, INFO, WARNING, ERROR\n",
    "    format='%(asctime)s %(levelname)s [%(name)s]: %(message)s',\n",
    "    handlers=[\n",
    "        # logging.FileHandler(default_log_filename, mode='w', encoding='utf-8'),\n",
    "        # # logging.StreamHandler()     # Console output also disabled\n",
    "    ],\n",
    "    force=True\n",
    ")\n",
    "\n",
    "# Default logger\n",
    "logger = logging.getLogger(\"EthereumPBS\")\n",
    "logger.info(\"Default logger initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transaction:\n",
    "    def __init__(self, rng, tx_id, arrival_time, gas_used, base_fee_per_gas, priority_fee_per_gas, sanctioned_type):\n",
    "        \"\"\"\n",
    "        Transaction object\n",
    "        - tx_id: unique transaction ID\n",
    "        - arrival_time: the time the transaction enters the Mempool\n",
    "        - proposed_block_id: the ID of the block where the transaction is included and finalized (initially None)\n",
    "        - proposed_time: the time the transaction is proposed with the block\n",
    "        - confirmed_time: the time the transaction is finally confirmed (initially None)\n",
    "        - transaction_type: only \"DeFi\" is retained\n",
    "        - gas_used: amount of gas used by the transaction\n",
    "        - gas_price: price the transaction is willing to pay per gas unit (in Gwei/gas)\n",
    "        - gas_fee: total gas fee = gas_price * gas_used (in Gwei)\n",
    "        - sanctioned_type: 0 = non-sanctioned, 1 = sanctioned\n",
    "        - reject_count: number of times the transaction has been rejected\n",
    "        \"\"\"\n",
    "        self.tx_id = tx_id\n",
    "        self.arrival_time = arrival_time        # Time when transaction enters Mempool\n",
    "        self.proposed_block_id = None           # Block ID in which the transaction is included and finalized\n",
    "        self.proposed_time = None           # Time the transaction is proposed (block proposal time)\n",
    "        self.confirmed_time = None           # Time the transaction is confirmed (block inclusion time)\n",
    "        self.is_proposed = False\n",
    "        self.is_confirmed = False\n",
    "        self.transaction_type = \"DeFi\"\n",
    "\n",
    "        self.gas_used = gas_used\n",
    "        self.base_fee_per_gas = base_fee_per_gas\n",
    "        self.priority_fee_per_gas = priority_fee_per_gas        # Priority fee per gas\n",
    "        self.base_fee = base_fee_per_gas * gas_used\n",
    "        self.priority_fee = priority_fee_per_gas * gas_used\n",
    "        self.gas_fee = self.base_fee + self.priority_fee\n",
    "\n",
    "        self.sanctioned_type = sanctioned_type\n",
    "\n",
    "        self.proposed_builder_id = None\n",
    "        self.selected_relay_id = None\n",
    "        self.proposer_validator_id = None\n",
    "\n",
    "        self.proposed_builder_policy = None\n",
    "        self.selected_relay_policy = None\n",
    "        self.proposer_validator_is_censoring = None\n",
    "\n",
    "\n",
    "    def update_proposed_time(self, block_id, proposed_time, \n",
    "                             builder_id, selected_relay_id, proposer_validator_id,\n",
    "                             builder_policy, selected_relay_policy, proposer_validator_is_censoring):\n",
    "        \"\"\"\n",
    "        Update proposal information of the transaction.\n",
    "        Ensure the transaction is proposed only once and not re-packed in later slots.\n",
    "        \"\"\"\n",
    "        if self.proposed_time is None:                    # Ensure it is updated only once\n",
    "            self.proposed_block_id = block_id                      # Assign the block ID to which the transaction is proposed\n",
    "            self.proposed_time = proposed_time             # Record the proposal time\n",
    "            self.is_proposed = True\n",
    "\n",
    "            self.proposed_builder_id = builder_id\n",
    "            self.selected_relay_id = selected_relay_id\n",
    "            self.proposer_validator_id = proposer_validator_id\n",
    "            self.proposed_builder_policy = builder_policy\n",
    "            self.selected_relay_policy = selected_relay_policy\n",
    "            self.proposer_validator_is_censoring = proposer_validator_is_censoring\n",
    "\n",
    "        else:\n",
    "            raise Exception(f\"Transaction {self.tx_id} has already been proposed.\")\n",
    "\n",
    "\n",
    "    def update_confirmed_time(self, confirmed_time):\n",
    "        \"\"\"\n",
    "        Update the confirmation time of the transaction.\n",
    "        Ensure it has been proposed before being confirmed, and is only confirmed once.\n",
    "        \"\"\"\n",
    "        if self.proposed_time is None:\n",
    "            raise Exception(f\"Transaction {self.tx_id} has not been proposed yet.\")\n",
    "        if self.confirmed_time is None:\n",
    "            self.confirmed_time = confirmed_time\n",
    "            self.is_confirmed = True\n",
    "        else:\n",
    "            raise Exception(f\"Transaction {self.tx_id} has already been confirmed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mempool:\n",
    "\n",
    "    def __init__(self, rng, tx_rate, sanctioned_probs=None):\n",
    "        \"\"\"\n",
    "        Mempool for storing transactions\n",
    "        - rng: random number generator\n",
    "        - tx_rate: transaction generation rate (transactions per second)\n",
    "        - tx_count: transaction counter to ensure unique `tx_id`\n",
    "        - pending_transactions: stores all unconfirmed transactions\n",
    "        - proposed_transactions: stores proposed transactions\n",
    "        - sanctioned_probs: probability distribution for sanction types (added)\n",
    "        \"\"\"\n",
    "        self.rng = rng\n",
    "        self.pending_transactions = {}      # Store unconfirmed transactions as a dictionary\n",
    "        self.proposed_transactions = {}     # Store proposed transactions\n",
    "        self.tx_rate = tx_rate\n",
    "        self.tx_count = 0\n",
    "        self.sanctioned_probs = sanctioned_probs or [0.995, 0.005]  \n",
    "        \n",
    "    def generate_transactions(self, current_time, simulation_time):\n",
    "        \"\"\"\n",
    "        Generate transactions within the given simulation_time,\n",
    "        using an exponential distribution for arrival intervals\n",
    "        \"\"\"\n",
    "        # Estimate the number of transactions to generate\n",
    "        estimated_tx_count = int((simulation_time - current_time) * self.tx_rate)\n",
    "        \n",
    "        # Generate all inter-arrival times at once\n",
    "        arrival_intervals = self.rng.exponential(1 / self.tx_rate, size=estimated_tx_count)\n",
    "        \n",
    "        # Batch-generate other random properties\n",
    "        gas_used_batch = self.rng.integers(90_000, 110_000, size=estimated_tx_count)\n",
    "        priority_fee_per_gas_batch = self.rng.uniform(0.1, 5, size=estimated_tx_count)           # Priority fee range: [0.1, 5] Gwei\n",
    "        sanctioned_batch = self.rng.choice([0, 1], size=estimated_tx_count, p=self.sanctioned_probs)\n",
    "  \n",
    "\n",
    "        # Create transactions iteratively\n",
    "        for i in range(estimated_tx_count):\n",
    "            current_time += arrival_intervals[i]\n",
    "\n",
    "            if current_time >= simulation_time:\n",
    "                break  # Stop early if the time exceeds simulation_time\n",
    "\n",
    "            self.tx_count += 1\n",
    "\n",
    "            # Create a new Transaction instance\n",
    "            tx = Transaction(\n",
    "                self.rng, \n",
    "                self.tx_count,    \n",
    "                current_time,\n",
    "                gas_used=gas_used_batch[i],\n",
    "                base_fee_per_gas = 3.44,           # Assumed fixed base fee (Gwei/gas), eventually burned\n",
    "                priority_fee_per_gas=priority_fee_per_gas_batch[i],     # Pass per_gas priority fee\n",
    "                sanctioned_type=sanctioned_batch[i]\n",
    "            )\n",
    "\n",
    "            # Store in pending transactions dictionary\n",
    "            self.pending_transactions[tx.tx_id] = tx\n",
    "\n",
    "    def update_transaction_proposed(self, proposed_block):\n",
    "        \"\"\"\n",
    "        Update proposal information of transactions in a proposed block\n",
    "        \"\"\"\n",
    "        for tx in proposed_block.transactions:\n",
    "            if tx.tx_id in self.pending_transactions:\n",
    "                tx.update_proposed_time(\n",
    "                    block_id=proposed_block.block_id, \n",
    "                    proposed_time=proposed_block.proposed_time,\n",
    "                    builder_id=proposed_block.builder_id,\n",
    "                    selected_relay_id=proposed_block.selected_relay_id,\n",
    "                    proposer_validator_id=proposed_block.proposer_validator_id,\n",
    "                    builder_policy=proposed_block.builder_policy,\n",
    "                    selected_relay_policy=proposed_block.selected_relay_policy,\n",
    "                    proposer_validator_is_censoring=proposed_block.proposer_validator_is_censoring\n",
    "                    )\n",
    "                \n",
    "                tx.update_confirmed_time(proposed_block.confirmed_time)\n",
    "\n",
    "                self.proposed_transactions[tx.tx_id] = tx  # Move to proposed_transactions\n",
    "                del self.pending_transactions[tx.tx_id]     # Remove from pending_transactions\n",
    "                # print(f\"Transaction {tx.tx_id} proposed in Block {proposed_block.block_id} at {proposed_block.proposed_time:.4f} sec.\")\n",
    "                logger.debug(f\"Tx {tx.tx_id} proposed in Block {proposed_block.block_id} at {proposed_block.proposed_time:.4f}s\")\n",
    "                logger.debug(f\"Tx {tx.tx_id} is removed from pending transactions to proposed transactions.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateBlock:\n",
    "    def __init__(self, builder_id, slot_no, parent_block_id, transactions, block_build_finish_time, \n",
    "                 block_count, block_gas_limit, total_gas_used, total_gas_fee, total_priority_fee, tx_counts):\n",
    "        \"\"\"\n",
    "        'CandidateBlock' represents a block constructed by a Builder\n",
    "        \"\"\"\n",
    "        self.block_id = f\"{builder_id}_{block_count}\"\n",
    "        self.builder_id = builder_id\n",
    "        self.slot_no = slot_no\n",
    "        self.parent_block_id = parent_block_id  # ID of the parent block\n",
    "        self.block_build_finish_time = block_build_finish_time\n",
    "        self.relay_approval_times = {}              # {relay_id: approval_time}\n",
    "        self.transactions = transactions\n",
    "        self.num_transactions = len(transactions)\n",
    "\n",
    "        self.total_gas_used = total_gas_used\n",
    "        self.total_gas_fee = total_gas_fee\n",
    "        self.total_priority_fee = total_priority_fee\n",
    "        self.tx_counts = tx_counts  # Transaction type statistics passed directly\n",
    "\n",
    "        if self.total_gas_used > block_gas_limit:\n",
    "            raise ValueError(\"Block gas usage exceeds the limit!\")\n",
    "        \n",
    "        self.proposed_time = None           # Time when the block is proposed, default is None\n",
    "        self.confirmed_time = None          # Time when the block is confirmed on-chain, default is None\n",
    "        self.builder_review_time = None         # Time spent on builder-side censorship review\n",
    "        self.relay_reject_count = 0\n",
    "        self.proposer_reject_count = 0\n",
    "        self.is_relay_approved = False\n",
    "        self.is_proposed = False\n",
    "        self.is_confirmed = False\n",
    "        self.selected_relay_id = None       # ID of the selected relay\n",
    "        \n",
    "        self.proposer_validator_id = None   # ID of the validator proposing the block \n",
    "\n",
    "        self.builder_profit = 0   # Builder's profit\n",
    "        self.proposer_profit = 0  # Proposer's profit\n",
    "        \n",
    "        self.builder_policy = None           # builder policy：'non', 'weak', 'strict'\n",
    "        self.selected_relay_policy = None               # relay policy：'non', 'censoring'\n",
    "        self.proposer_validator_is_censoring = None      # validator policy：‘true’, ‘false’\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, CandidateBlock) and self.block_id == other.block_id\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.block_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CensorshipPolicy:\n",
    "    \"\"\"\n",
    "    Manage the censorship behavior of different nodes (Builder, Relay) and compute its effects.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, builder_policy, relay_policy, \n",
    "                 builder_review_time_per_tx=0.002,  \n",
    "                 relay_review_time_per_tx=0.001,    \n",
    "                 type_1_rejection_prob_builder=1.0, \n",
    "                 type_1_rejection_prob_relay=1.0,\n",
    "                 weak_detection_prob=1.0,           \n",
    "                 rng=np.random.default_rng()):\n",
    "        \"\"\"\n",
    "        Initialize the censorship policy.\n",
    "        :param builder_policy: Censorship policy of the Builder (\"non\": no censorship, \"weak\": weak censorship, \"strict\": strict censorship)\n",
    "        :param relay_policy: Censorship policy of the Relay (\"non\": no censorship, \"censoring\": with censorship)\n",
    "        :param rng: Random number generator\n",
    "        - type_1_rejection_prob_builder: Probability that the Builder rejects a transaction with sanctioned_type==1 (range 0 to 1)\n",
    "        - type_1_rejection_prob_relay: Probability that the Relay rejects a transaction with sanctioned_type==1 (range 0 to 1)\n",
    "        \"\"\"\n",
    "        self.builder_policy = builder_policy\n",
    "        self.relay_policy = relay_policy\n",
    "\n",
    "        self.builder_review_time_per_tx = builder_review_time_per_tx        # Builder's review time per transaction\n",
    "        self.relay_review_time_per_tx = relay_review_time_per_tx        # Relay's review time per transaction\n",
    "\n",
    "        # Rejection probability for transactions involving sanctioned addresses (sanctioned_type == 1)\n",
    "        self.type_1_rejection_prob_builder = type_1_rejection_prob_builder\n",
    "        self.type_1_rejection_prob_relay = type_1_rejection_prob_relay\n",
    "        self.weak_detection_prob = weak_detection_prob                \n",
    "\n",
    "        self.rng = rng\n",
    "\n",
    "        # Track transaction IDs that have been rejected once under weak censorship\n",
    "        self.weak_censored_tx_ids = set() \n",
    "\n",
    "\n",
    "\n",
    "    def builder_censorship(self, tx):\n",
    "        \"\"\"\n",
    "        Apply builder-side censorship to a transaction.\n",
    "        This affects the probability that a transaction is included in a block and adds review latency.\n",
    "\n",
    "        :param tx: Transaction object (with attribute sanctioned_type: 0 = not sanctioned, 1 = sanctioned)\n",
    "        :return: (is_rejected: bool, review_delay: float)\n",
    "        \"\"\"\n",
    "        # print(f\"Builder checking tx {tx.tx_id} with sanctioned_type={tx.sanctioned_type}. Builder censorship policy {self.builder_policy}\")\n",
    "        logger.debug(f\"Builder checking tx {tx.tx_id} with sanctioned_type={tx.sanctioned_type}, priority_fee={tx.priority_fee}. Builder censorship policy {self.builder_policy}\")\n",
    "        \n",
    "        if self.builder_policy == \"non\":\n",
    "            return False, 0  # No censorship, no delay\n",
    "\n",
    "        review_time = self.builder_review_time_per_tx  \n",
    "\n",
    "        if tx.sanctioned_type == 1:\n",
    "            if self.builder_policy == \"strict\":\n",
    "                # Strict censorship: reject based on probability\n",
    "                if self.rng.random() <= self.type_1_rejection_prob_builder:\n",
    "                    return True, review_time    \n",
    "                else:\n",
    "                    return False, review_time\n",
    "\n",
    "            elif self.builder_policy == \"weak\":\n",
    "                if self.rng.random() > self.weak_detection_prob:            # Missed detection with some probability\n",
    "                    logger.debug(f\"  - tx {tx.tx_id} weakly censored but missed detection.\")\n",
    "                    return False, review_time\n",
    "                if tx.tx_id not in self.weak_censored_tx_ids:\n",
    "                    self.weak_censored_tx_ids.add(tx.tx_id)\n",
    "                    logger.debug(f\"  - tx {tx.tx_id} weakly censored first time, rejected.\")\n",
    "                    return True, review_time        # First time is rejected\n",
    "                else:\n",
    "                    logger.debug(f\"  - tx {tx.tx_id} weakly censored before, accepted now.\")\n",
    "                    return False, review_time           # Accepted on second and subsequent checks\n",
    "\n",
    "        return False, review_time\n",
    "\n",
    "\n",
    "    def relay_censorship(self, block):\n",
    "        \"\"\"\n",
    "        Apply relay-side censorship to a block.\n",
    "        This affects the block's propagation delay.\n",
    "        Note: As a network relay, a relay should not reorder blocks but process them in FIFO order.\n",
    "\n",
    "        :param block: Block object (contains a list of transactions, each with a sanctioned_type)\n",
    "        :return: (is_rejected: bool, review_delay: float)\n",
    "        \"\"\"\n",
    "        # print(f\"Relay checking block {block.block_id} with {len(block.transactions)} transactions. Relay censorship policy {self.relay_policy}\")\n",
    "        logger.debug(f\"Relay checking block {block.block_id} with {len(block.transactions)} transactions and {block.total_priority_fee} priority fee. Relay censorship policy {self.relay_policy}\")\n",
    "        \n",
    "        if self.relay_policy == \"non\":\n",
    "            return False, 0\n",
    "\n",
    "        total_review_time = 0\n",
    "\n",
    "        for tx in block.transactions:\n",
    "            # print(f\"  - tx {tx.tx_id} sanctioned_type={tx.sanctioned_type}\")\n",
    "            logger.debug(f\"  - tx {tx.tx_id} sanctioned_type={tx.sanctioned_type}\")\n",
    "            \n",
    "            review_time = self.relay_review_time_per_tx  \n",
    "            total_review_time += review_time   \n",
    "\n",
    "            if self.relay_policy == \"censoring\":\n",
    "                if tx.sanctioned_type == 1 and self.rng.random() <= self.type_1_rejection_prob_relay:\n",
    "                    # print(f\" Rejected block {block.block_id} due to tx {tx.tx_id}.\")\n",
    "                    logger.debug(f\" Rejected block {block.block_id} due to tx {tx.tx_id}.\")\n",
    "                    return True, total_review_time\n",
    "\n",
    "\n",
    "        # print(f\"Block {block.block_id} passed censorship.\")\n",
    "        logger.debug(f\"Block {block.block_id} passed censorship.\")\n",
    "        \n",
    "        return False, total_review_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Builder:\n",
    "\n",
    "    def __init__(self, mempool, rng, builder_id, censorship_policy, relays, \n",
    "                 block_gas_limit=16_000_000, skip_probability=0.1, is_censoring=False, base_block_build_time=4.0, proposer_reward_ratio=0.95, model=None):\n",
    "        \"\"\"\n",
    "        The Builder selects transactions from the Mempool and constructs blocks to submit to Relays.\n",
    "        - mempool: Mempool object\n",
    "        - rng: random number generator\n",
    "        - builder_id: unique identifier for the builder\n",
    "        - block_gas_limit: Ethereum block gas limit\n",
    "        - skip_probability: probability of randomly skipping transactions in the mempool (default: 10%)\n",
    "        - is_censoring: whether the builder performs censorship\n",
    "        - relays: list of available Relays to submit blocks to\n",
    "        \"\"\"\n",
    "        self.mempool = mempool\n",
    "        self.rng = rng\n",
    "        self.builder_id = builder_id\n",
    "        self.block_gas_limit = block_gas_limit\n",
    "        self.skip_probability = skip_probability            # Probability of skipping a transaction\n",
    "        self.block_count = 0                                # Count of blocks built by this builder\n",
    "        self.is_censoring = is_censoring            # Whether censorship is applied\n",
    "        # self.seen_transactions = set()                      # Previously proposed but unconfirmed transactions\n",
    "        self.relays = relays                                # Relays this builder can submit to\n",
    "        self.base_block_build_time = base_block_build_time  # Base time to build a block\n",
    "        self.model = model\n",
    "        self.proposer_reward_ratio = proposer_reward_ratio  \n",
    "\n",
    "        # Maintain a set of transactions rejected under weak censorship\n",
    "        self.weak_censored_tx_ids = set()  \n",
    "\n",
    "        # Assign weak_censored_tx_ids to the censorship policy\n",
    "        self.censorship_policy = censorship_policy\n",
    "        self.censorship_policy.weak_censored_tx_ids = self.weak_censored_tx_ids\n",
    "\n",
    "    # Initialize local blockchain with genesis block\n",
    "        genesis_block = CandidateBlock(\n",
    "            builder_id=\"GENESIS\",\n",
    "            slot_no=0,\n",
    "            parent_block_id=None,\n",
    "            transactions=[],                # No transactions in genesis block\n",
    "            block_build_finish_time=0,\n",
    "            block_count=0,\n",
    "            block_gas_limit=0,\n",
    "            total_gas_used=0,           \n",
    "            total_gas_fee=0,            \n",
    "            total_priority_fee=0,\n",
    "            tx_counts={0: 0, 1: 0},  \n",
    "        )\n",
    "        self.local_blockchain = [genesis_block]\n",
    "\n",
    "    def get_sorted_transactions_from_mempool(self, current_time):\n",
    "        \"\"\"\n",
    "        Fetch transactions from the mempool and sort them by descending gas priority fee.\n",
    "        - Skip transactions that arrive after the current time\n",
    "        - Randomly skip some transactions to simulate imperfect competition\n",
    "        \"\"\"\n",
    "        sorted_transactions = sorted(\n",
    "            (tx for tx in self.mempool.pending_transactions.values() \n",
    "             if tx.arrival_time <= current_time),\n",
    "            key=lambda tx: tx.priority_fee_per_gas,     # Sort by priority fee per gas\n",
    "            reverse=True\n",
    "        )\n",
    "        return [tx for tx in sorted_transactions if self.rng.random() > self.skip_probability]\n",
    "\n",
    "    def get_latest_chain_head(self):\n",
    "        \"\"\"\n",
    "        Get the latest block ID to use as the parent block of the new candidate block\n",
    "        \"\"\"\n",
    "        return self.local_blockchain[-1].block_id \n",
    "\n",
    "    def build_candidate_block(self, current_time, slot_no):\n",
    "        \"\"\"\n",
    "        Construct a candidate block using transactions from the Mempool.\n",
    "        1. Select transactions in descending order of gas fee\n",
    "        2. Ensure total gas used stays within the gas limit\n",
    "        \"\"\"\n",
    "        # # Check if the current time is less than the model's time\n",
    "        # if hasattr(self, 'model') and self.model and current_time < self.model.time:\n",
    "        #     raise RuntimeError(f\"[Time Error] build_candidate_block: current_time={current_time:.4f} < model.time={self.model.time:.4f}\")\n",
    " \n",
    "\n",
    "        parent_block_id = self.get_latest_chain_head()  \n",
    "\n",
    "        block_transactions = []\n",
    "        total_gas_used = 0\n",
    "        total_gas_fee = 0                       \n",
    "        total_priority_fee = 0                 \n",
    "        tx_counts = {0: 0, 1: 0}                \n",
    "        over_limit_count = 0                     # Count of consecutively skipped transactions due to gas limit\n",
    "        builder_review_time = 0                 # Total time spent on censorship review\n",
    "\n",
    "        sorted_transactions = self.get_sorted_transactions_from_mempool(current_time)\n",
    "        \n",
    "        for tx in sorted_transactions:     \n",
    "            if total_gas_used + tx.gas_used > self.block_gas_limit:\n",
    "                over_limit_count += 1           \n",
    "                if over_limit_count >= 5:\n",
    "                    break                   # Stop after 5 consecutive over-limit transactions\n",
    "                continue            # Try next transaction\n",
    "            \n",
    "            if self.is_censoring:\n",
    "                is_rejected, review_time = self.censorship_policy.builder_censorship(tx)\n",
    "                # print(f\"[{current_time:.4f}], Builder {self.builder_id} censorship check: tx={tx.tx_id}, is_rejected={is_rejected}, review_time={review_time}\")\n",
    "                logger.debug(f\"[{current_time:.4f}], Builder {self.builder_id} censorship check: tx={tx.tx_id}, is_rejected={is_rejected}, review_time={review_time}\")\n",
    "                builder_review_time += review_time         \n",
    "                if is_rejected:\n",
    "                    continue         \n",
    "                \n",
    "            block_transactions.append(tx)\n",
    "            total_gas_used += tx.gas_used\n",
    "            total_gas_fee += tx.gas_fee              \n",
    "            total_priority_fee += tx.priority_fee              \n",
    "            tx_counts[tx.sanctioned_type] += 1         \n",
    "            over_limit_count = 0            \n",
    "\n",
    "        # If no transactions were selected, return None\n",
    "        if not block_transactions:\n",
    "            logger.debug(f\"[{current_time:.4f}]. Builder {self.builder_id} no tx available at {current_time:.4f}.\"\n",
    "                         f\"Next try at {current_time + self.base_block_build_time:.4f}\")\n",
    "            # print(f\"[{current_time:.4f}], Builder {self.builder_id} has no transactions to build block at {current_time:.4f}.\"\n",
    "            #      f\"Next try at {current_time + self.base_block_build_time:.4f}\")\n",
    "            return None, self.base_block_build_time + builder_review_time\n",
    "\n",
    "        # Calculate the final build time\n",
    "        total_build_time = self.base_block_build_time + builder_review_time\n",
    "        final_time = current_time + total_build_time\n",
    "\n",
    "        # Update the block count\n",
    "        self.block_count += 1\n",
    "\n",
    "        # Create the candidate block with all necessary information\n",
    "        candidate_block = CandidateBlock(\n",
    "            builder_id=self.builder_id,\n",
    "            slot_no=slot_no,                    \n",
    "            parent_block_id=parent_block_id,   \n",
    "            transactions=block_transactions,\n",
    "            block_build_finish_time=final_time,         \n",
    "            block_count=self.block_count,\n",
    "            block_gas_limit=self.block_gas_limit,\n",
    "            total_gas_used=total_gas_used,     \n",
    "            total_gas_fee=total_gas_fee,        \n",
    "            total_priority_fee=total_priority_fee,       \n",
    "            tx_counts=tx_counts                 \n",
    "        )\n",
    "\n",
    "        candidate_block.builder_review_time = builder_review_time\n",
    "        candidate_block.proposer_profit = total_priority_fee * self.proposer_reward_ratio\n",
    "        candidate_block.builder_profit = total_priority_fee * (1 - self.proposer_reward_ratio)\n",
    "        candidate_block.builder_policy = self.censorship_policy.builder_policy\n",
    "\n",
    "\n",
    "        \n",
    "        logger.debug(\n",
    "            f\"[{current_time:.4f}]. Builder {self.builder_id} built block {candidate_block.block_id} \"\n",
    "            f\"(Slot {candidate_block.slot_no}, TxCount: {candidate_block.num_transactions}, Gas Used: {candidate_block.total_gas_used}, \"\n",
    "            f\"GasFee: {candidate_block.total_gas_fee:.2f} Gwei), PriorityFee: {candidate_block.total_priority_fee} Gwei. Finish Time: {candidate_block.block_build_finish_time:.4f} sec. \"\n",
    "        )\n",
    "        \n",
    "        # print(f\"[{current_time:.4f}]. Builder {self.builder_id} built block {candidate_block.block_id} for Slot {candidate_block.slot_no} \"\n",
    "        #     f\"with {candidate_block.num_transactions} transactions and parent {candidate_block.parent_block_id}. \"\n",
    "        #     f\"Total Gas Used: {candidate_block.total_gas_used}, Total Gas Fee: {candidate_block.total_gas_fee} Gwei. \"\n",
    "        #     f\"Review Time: {builder_review_time:.4f} sec, base block build time: {self.base_block_build_time:.4f} sec. \"\n",
    "        #     f\"Finish Time: {candidate_block.current_time:.4f}\")\n",
    "        \n",
    "        return candidate_block, total_build_time      \n",
    "\n",
    "\n",
    "    def submit_block_to_relays(self, candidate_block, submit_time, model):\n",
    "        \"\"\"\n",
    "        Immediately submit the candidate block to all available Relays\n",
    "        \"\"\"\n",
    "        # # Check if the submit_time is less than the model's time\n",
    "        # if submit_time < model.time:\n",
    "        #     raise RuntimeError(f\"[Time Error] submit_block_to_relays: submit_time={submit_time:.4f} < model.time={model.time:.4f}\")\n",
    "  \n",
    "        for relay in self.relays:\n",
    "            relay.receive_block(candidate_block, submit_time, model)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relay:\n",
    "    def __init__(self, relay_id, censorship_policy, is_censoring=False, base_relay_process_time=1.0):\n",
    "        \"\"\"\n",
    "        Relay receives CandidateBlocks submitted by multiple Builders.\n",
    "        - is_censoring: whether the relay performs censorship (controlled externally)\n",
    "        \"\"\"\n",
    "        self.relay_id = relay_id\n",
    "        self.censorship_policy = censorship_policy          # Associated censorship policy\n",
    "        self.is_censoring = is_censoring        # Whether this relay applies censorship\n",
    "        self.received_blocks = []           # Blocks awaiting censorship\n",
    "        self.ready_blocks = []          # Blocks that passed review and are ready for proposer selection\n",
    "        self.base_relay_process_time = base_relay_process_time          # Base time required to process a block\n",
    "\n",
    "    def clear_received_ready_blocks(self):\n",
    "        \"\"\"Clear old blocks at the beginning of a new slot\"\"\"\n",
    "        self.received_blocks.clear()\n",
    "        self.ready_blocks.clear()\n",
    "        # print(f\"Relay {self.relay_id} clears old blocks at slot start\")\n",
    "        logger.debug(f\"Relay {self.relay_id} cleared old blocks\")\n",
    "\n",
    "    def receive_block(self, candidate_block, current_time, model):\n",
    "        \"\"\"A Builder submits a block to the Relay; Relay queues it for future processing\"\"\"\n",
    "        self.received_blocks.append(candidate_block)\n",
    "        # print(f\"Relay {self.relay_id} received block {candidate_block.block_id} from Builder {candidate_block.builder_id}\")\n",
    "        logger.debug(f\"Relay {self.relay_id} received block {candidate_block.block_id} from Builder {candidate_block.builder_id}\")\n",
    "\n",
    "    def process_received_blocks(self, current_time, model):\n",
    "        \"\"\"\n",
    "        Relay processes received blocks when RelayProcessingEvent is triggered.\n",
    "        Applies censorship if enabled and schedules approval results.\n",
    "        \"\"\"\n",
    "        if not self.received_blocks:\n",
    "            return    # No blocks to process\n",
    "\n",
    "        blocks_to_process = self.received_blocks.copy()\n",
    "        self.received_blocks.clear()\n",
    "\n",
    "        block_results = []\n",
    "        max_process_time = 0\n",
    "        \n",
    "        # Review each block in parallel and compute max processing time\n",
    "        for block in blocks_to_process:\n",
    "\n",
    "            if self.is_censoring:\n",
    "                is_rejected, review_time = self.censorship_policy.relay_censorship(block)\n",
    "            else:\n",
    "                is_rejected, review_time = False, 0     # No censorship = no review delay\n",
    "\n",
    "            total_process_time = self.base_relay_process_time + review_time      \n",
    "            max_process_time = max(max_process_time, total_process_time)      \n",
    "\n",
    "            block_results.append((block, is_rejected))\n",
    "        \n",
    "        # Schedule all block review outcomes to be finalized at the same future time\n",
    "        ready_time = current_time + max_process_time\n",
    "        model.schedule_event(ready_time, self.finalize_block_processing, ready_time, block_results)\n",
    "        # print(f\"[{current_time:.4f}] Relay {self.relay_id} started parallel processing {len(block_results)} blocks, \"\n",
    "        #       f\"expected finish at {ready_time:.4f}\")\n",
    "        logger.debug(f\"[{current_time:.4f}]. Relay {self.relay_id} started parallel processing {len(block_results)} blocks, \"\n",
    "                      f\"expected finish at {ready_time:.4f}\")\n",
    "        \n",
    "    def finalize_block_processing(self, current_time, block_results):\n",
    "        \"\"\"Finalize approval/rejection of all reviewed blocks\"\"\"\n",
    "        for block, is_rejected in block_results:\n",
    "            if not is_rejected:\n",
    "                block.is_relay_approved = True\n",
    "                block.relay_approval_times[self.relay_id] = current_time\n",
    "                self.ready_blocks.append(block)\n",
    "                # print(f\"[{current_time:.4f}], Relay {self.relay_id} approved block {block.block_id}\")\n",
    "                logger.debug(f\"[{current_time:.4f}], Relay {self.relay_id} approved block {block.block_id}\")\n",
    "            else:\n",
    "                block.relay_reject_count += 1\n",
    "                # print(f\"[{current_time:.4f}], Relay {self.relay_id} rejected block {block.block_id}\")\n",
    "                logger.debug(f\"[{current_time:.4f}], Relay {self.relay_id} rejected block {block.block_id}\")\n",
    "\n",
    "\n",
    "    def get_best_ready_block(self, latest_chain_head, current_time):\n",
    "        \"\"\"\n",
    "        Select the best approved block whose parent matches the latest chain head and is fully approved.\n",
    "        \"\"\"\n",
    "        valid_blocks = []\n",
    "\n",
    "        for block in self.ready_blocks:\n",
    "            # Ensure correct parent block\n",
    "            if block.parent_block_id != latest_chain_head:\n",
    "                logger.debug(\n",
    "                    f\"Relay {self.relay_id} skipped block {block.block_id} due to invalid parent block. \"\n",
    "                    f\"Expected {latest_chain_head}, got {block.parent_block_id}.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Ensure approval is complete and not in the future\n",
    "            approval_time = block.relay_approval_times.get(self.relay_id)\n",
    "            if approval_time is None or approval_time > current_time:\n",
    "                logger.debug(\n",
    "                    f\"Relay {self.relay_id} skipped block {block.block_id} due to incomplete approval. \"\n",
    "                    f\"Approval time: {approval_time}, current time: {current_time}.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            valid_blocks.append(block)\n",
    "\n",
    "        if not valid_blocks:\n",
    "            return None\n",
    "\n",
    "        max_profit = max(block.proposer_profit for block in valid_blocks)\n",
    "        best_blocks = [block for block in valid_blocks if block.proposer_profit == max_profit]\n",
    "\n",
    "        return random.choice(best_blocks)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proposer:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The Proposer is responsible for selecting the best block from the Relays\n",
    "        and maintaining the local view of the blockchain.\n",
    "        \"\"\"\n",
    "        # Local blockchain storage, initialized with the genesis block\n",
    "        genesis_block = CandidateBlock(\n",
    "            builder_id=\"GENESIS\",\n",
    "            slot_no=0,\n",
    "            parent_block_id=None,\n",
    "            transactions=[],               # Genesis block has no transactions\n",
    "            block_build_finish_time=0,\n",
    "            block_count=0,\n",
    "            block_gas_limit=0,          # Genesis block has no gas limit\n",
    "            total_gas_used=0,           \n",
    "            total_gas_fee=0,            \n",
    "            total_priority_fee=0,       \n",
    "            tx_counts={0: 0, 1: 0},  \n",
    "        )\n",
    "        self.local_blockchain = [genesis_block]\n",
    "        self.empty_block_counter = 0            # Counter for empty blocks proposed by the Proposer\n",
    "\n",
    "\n",
    "    def get_latest_chain_head(self):\n",
    "        \"\"\"\n",
    "        Return the current chain head of the local blockchain.\n",
    "        \"\"\"\n",
    "        return self.local_blockchain[-1].block_id  \n",
    "    \n",
    "    def propose_block(self, relays, selected_validator, current_time, slot_no):\n",
    "        \"\"\"\n",
    "        Select the block with the highest proposer profit from all ready blocks across relays.\n",
    "        Ensure its parent matches the current chain head.\n",
    "        \"\"\"\n",
    "        latest_chain_head = self.get_latest_chain_head()  \n",
    "        valid_blocks = []\n",
    "        relay_sources = defaultdict(list)           # Track which relays each block came from\n",
    "        \n",
    "        for relay in relays:\n",
    "            block = relay.get_best_ready_block(latest_chain_head, current_time) \n",
    "            if block:\n",
    "                valid_blocks.append(block)\n",
    "                relay_sources[block.block_id].append(relay.relay_id)  \n",
    "\n",
    "        if valid_blocks:\n",
    "            # Choose the block with the highest proposer profit\n",
    "            max_proposer_profit = max(block.proposer_profit for block in valid_blocks)\n",
    "            top_blocks = [block for block in valid_blocks if block.proposer_profit == max_proposer_profit]\n",
    "\n",
    "            # If multiple blocks tie, select randomly\n",
    "            proposed_block = random.choice(top_blocks)\n",
    "            proposed_block.selected_relay_id = random.choice(relay_sources[proposed_block.block_id])\n",
    "            \n",
    "            # Set proposal and confirmation timestamps\n",
    "            proposed_block.is_proposed = True\n",
    "            proposed_block.proposed_time = current_time + 1\n",
    "            proposed_block.is_confirmed = True\n",
    "            proposed_block.confirmed_time = current_time + 12\n",
    "            proposed_block.proposer_validator_id = selected_validator.validator_id  \n",
    "            \n",
    "            # Retrieve selected relay instance to record its policy\n",
    "            selected_relay = next((relay for relay in relays if relay.relay_id == proposed_block.selected_relay_id), None)\n",
    "            if selected_relay is None:\n",
    "                raise Exception(f\"Relay {proposed_block.selected_relay_id} not found in provided relays list!\")\n",
    "\n",
    "            proposed_block.selected_relay_policy = selected_relay.censorship_policy.relay_policy\n",
    "            proposed_block.proposer_validator_is_censoring = selected_validator.is_censoring\n",
    "\n",
    "            # print(f\"Proposer selected block {proposed_block.block_id} from Relay {proposed_block.selected_relay_id} at Slot Time {current_time}\")\n",
    "            logger.debug(f\"[{current_time:.4f}]. Slot {slot_no}, Validator {selected_validator.validator_id} proposed block {proposed_block.block_id} from Relay {proposed_block.selected_relay_id}.\")\n",
    "            \n",
    "            # All other valid blocks are considered rejected\n",
    "            for block in valid_blocks:\n",
    "                if block != proposed_block:\n",
    "                    block.proposer_reject_count += 1  \n",
    "                    \n",
    "        else:\n",
    "            if slot_no == 0:\n",
    "                # If it's the initial slot, no block is proposed\n",
    "                # print(f\"[{current_time:.4f}], Slot {slot_no} (initial slot), no blocks available yet. Returning None.\")\n",
    "                logger.debug(f\"[{current_time:.4f}], Slot {slot_no} (initial slot), no blocks available yet. Returning None.\")\n",
    "                return None\n",
    "            \n",
    "            # If no valid block is found and it's not the first slot, create an empty block\n",
    "            self.empty_block_counter += 1\n",
    "            proposed_block = CandidateBlock(\n",
    "                builder_id=\"PROPOSER\",\n",
    "                slot_no=slot_no,\n",
    "                parent_block_id=latest_chain_head,\n",
    "                transactions=[],\n",
    "                block_build_finish_time=current_time,\n",
    "                block_count=self.empty_block_counter,\n",
    "                block_gas_limit=0,\n",
    "                total_gas_used=0,           \n",
    "                total_gas_fee=0,            \n",
    "                total_priority_fee=0,       \n",
    "                tx_counts={0: 0, 1: 0},  \n",
    "            )\n",
    "            proposed_block.builder_profit = 0\n",
    "            proposed_block.proposer_profit = 0\n",
    "            proposed_block.proposer_validator_id = selected_validator.validator_id \n",
    "            proposed_block.is_proposed = True\n",
    "            proposed_block.proposed_time = current_time + 1\n",
    "            proposed_block.is_confirmed = True\n",
    "            proposed_block.confirmed_time = current_time + 12\n",
    "            proposed_block.selected_relay_id = None\n",
    "            proposed_block.builder_policy = None\n",
    "            proposed_block.selected_relay_policy = None\n",
    "            proposed_block.proposer_validator_is_censoring = selected_validator.is_censoring\n",
    "            # print(f\"[{current_time:.4f}], Proposer generated EMPTY block {proposed_block.block_id} at Slot {slot_no}\")\n",
    "            logger.info(f\"[{current_time:.4f}]. Slot {slot_no}, Validator {selected_validator.validator_id} proposed EMPTY block {proposed_block.block_id}.\")\n",
    "\n",
    "        return proposed_block\n",
    "\n",
    "    def update_local_blockchain(self, proposed_block):\n",
    "        \"\"\"\n",
    "        Update the local blockchain with the newly proposed block.\n",
    "        \"\"\"    \n",
    "        self.local_blockchain.append(proposed_block)\n",
    "        # print(f\"Proposer added Block {proposed_block.block_id} to local blockchain.\")\n",
    "        logger.debug(f\"Proposer added Block {proposed_block.block_id} to local blockchain.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator:\n",
    "    def __init__(self, validator_id, connected_relays, is_censoring=False):\n",
    "        self.validator_id = validator_id\n",
    "        self.connected_relays = connected_relays\n",
    "        self.is_censoring = is_censoring            # True if connected to censoring relay, False otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedTimeEvent:\n",
    "    def __init__(self, model, interval=None, start_time=0, offset=0, rng=None):\n",
    "        \"\"\"\n",
    "        Base class for events triggered at fixed intervals.\n",
    "        :param interval: Fixed time interval between events (in seconds); if `None`, the `event()` method must set `next_event`\n",
    "        :param start_time: Start time of the first event (default is 0)\n",
    "        :param rng: Optional random number generator\n",
    "        \"\"\"\n",
    "        if interval is not None and interval <= 0:\n",
    "            raise ValueError(\"Interval must be positive or None.\")\n",
    "\n",
    "        self.interval = interval            # Fixed time interval; None means dynamically calculated\n",
    "        self.offset = offset        # Offset before the first event\n",
    "\n",
    "        self.next_event = start_time + self.offset      # Time of the next scheduled event\n",
    "        \n",
    "        self.rng = rng          # Optional RNG, used in derived classes if needed\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.counter = 0        # Track how many times the event has been triggered\n",
    "\n",
    "    def event(self):\n",
    "        \"\"\"\n",
    "        Method to be executed when the event is triggered (must be implemented by subclasses)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement this method.\")\n",
    "\n",
    "    def reset(self, start_time=0):\n",
    "        \"\"\"\n",
    "        Reset the event's starting time.\n",
    "        \"\"\"\n",
    "        self.next_event = start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockBuildingEvent(FixedTimeEvent):\n",
    "    def __init__(self, builder, model, rng=None, offset=4):\n",
    "        \"\"\"\n",
    "        Event class for Builders to build blocks periodically.\n",
    "        Each Builder runs independently.\n",
    "        \"\"\"\n",
    "        super().__init__(model=model, interval=None, start_time=0, offset=offset, rng=rng)\n",
    "        self.builder = builder\n",
    "\n",
    "    def event(self):\n",
    "        \"\"\"Trigger the Builder to build a block and submit it to the Relay.\"\"\"\n",
    "        current_time = self.next_event  \n",
    "        \n",
    "        slot_no =  int(current_time // 12 + 1)   # Dynamically calculate the slot number. Builders build for the next slot, so add 1.\n",
    "\n",
    "        candidate_block, total_build_time = self.builder.build_candidate_block(current_time, slot_no)\n",
    "\n",
    "        if candidate_block:\n",
    "            submit_time = current_time + total_build_time\n",
    "            # Schedule block submission to relays after build is complete\n",
    "            self.model.schedule_event(submit_time, self.builder.submit_block_to_relays, candidate_block, submit_time, self.model)  \n",
    "            # print(f\"Builder {self.builder.builder_id} submits block {candidate_block.block_id} to Relay at {submit_time:.4f}\")\n",
    "            logger.debug(f\"Builder {self.builder.builder_id} submits block {candidate_block.block_id} to Relay at {submit_time:.4f}\")\n",
    "\n",
    "            # Add block to the global list of all candidate blocks\n",
    "            self.model.schedule_event(submit_time, self.model.all_candidate_blocks.append, candidate_block) \n",
    "            # print(f\"Builder {self.builder.builder_id} added block {candidate_block.block_id} to all_candidate_blocks at {submit_time:.4f}\")\n",
    "            logger.debug(f\"Builder {self.builder.builder_id} added block {candidate_block.block_id} to all_candidate_blocks at {submit_time:.4f}\")\n",
    "        \n",
    "\n",
    "        # # Schedule the next block-building event\n",
    "        next_build_time = current_time + total_build_time\n",
    "        self.next_event = next_build_time\n",
    "        self.model.schedule_event(next_build_time, self.event)\n",
    "\n",
    "        # print(f\"Builder {self.builder.builder_id}, current time {current_time:.4f}, next event at {next_build_time:.4f} (after {total_build_time:.4f} sec)\")\n",
    "        logger.debug(f\"Builder {self.builder.builder_id}, current time {current_time:.4f}, next event at {next_build_time:.4f} (after {total_build_time:.4f} sec)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelayProcessingEvent(FixedTimeEvent):\n",
    "    def __init__(self, relay, model, interval=2, rng=None, offset=6.5):\n",
    "        \"\"\"\n",
    "        Event class for Relays to periodically process and review received blocks.\n",
    "        Each Relay runs independently.\n",
    "        \"\"\"\n",
    "        super().__init__(model=model, interval=interval, start_time=0, offset=offset, rng=rng)\n",
    "        self.relay = relay\n",
    "\n",
    "    def event(self):\n",
    "        \"\"\"Trigger the Relay to process its 'received_blocks' queue.\"\"\"\n",
    "        current_time = self.next_event  \n",
    "        self.relay.process_received_blocks(current_time, self.model)\n",
    "\n",
    "        # Schedule the next relay processing event\n",
    "        self.next_event = current_time + self.interval\n",
    "        self.model.schedule_event(self.next_event, self.event)\n",
    "\n",
    "        logger.debug(f\"Relay {self.relay.relay_id} processed blocks at {current_time:.4f} and scheduled next processing at {self.next_event:.4f}\")\n",
    "        # print(f\"Relay {self.relay.relay_id} processed blocks at {current_time:.4f} and scheduled next processing at {self.next_event:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlotStartEvent(FixedTimeEvent):\n",
    "    def __init__(self, proposer, builders, relays, validators, mempool, rng=None, model=None):\n",
    "        \"\"\"\n",
    "        Event triggered at the start of each slot.\n",
    "        Responsibilities include:\n",
    "        - Proposer selects the best block\n",
    "        - Relays clear old blocks\n",
    "        - Update transaction and block proposed time\n",
    "        - Builders and Proposer update their local blockchain\n",
    "        - Mempool clears confirmed transactions (applied at Slot N+1)\n",
    "        \"\"\"\n",
    "        super().__init__(model=model, interval=12, start_time=0, rng=rng)\n",
    "        self.proposer = proposer\n",
    "        self.builders = builders\n",
    "        self.relays = relays\n",
    "        self.validators = validators\n",
    "        self.mempool = mempool\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def event(self):\n",
    "        \"\"\"Execute actions at the beginning of each slot.\"\"\"\n",
    "        current_time = self.next_event\n",
    "        slot_no = int(current_time // self.interval)       # Dynamically calculate the slot number\n",
    "\n",
    "        # print(f\"Slot {slot_no} starts at {current_time:.4f}\")\n",
    "        logger.info(f\"Slot {slot_no} starts at {current_time:.4f}\")\n",
    "\n",
    "\n",
    "        # Step 1: Select a validator and retrieve its connected relays\n",
    "        selected_validator = self.rng.choice(self.validators)\n",
    "\n",
    "        selected_relays = selected_validator.connected_relays\n",
    "\n",
    "        selected_relay_ids = [relay.relay_id for relay in selected_relays]\n",
    "        logger.info(f\"Slot {slot_no}: selected Validator {selected_validator.validator_id} \"\n",
    "                    f\"(censoring={selected_validator.is_censoring}) connected relays: {selected_relay_ids}\")\n",
    "\n",
    "\n",
    "        # Step 2: Proposer selects the best block from relays and proposes it\n",
    "        # print(f\"[{current_time:.4f}], Proposer selects block from Relays at Slot {slot_no}\")\n",
    "        logger.debug(f\"[{current_time:.4f}], Proposer selects block from Relays at Slot {slot_no}\")\n",
    "        proposed_block = self.proposer.propose_block(selected_relays, selected_validator, current_time, slot_no)\n",
    "        \n",
    "\n",
    "        # Step 3: Update transaction/block states, relay/builder states\n",
    "        if proposed_block:\n",
    "            self.mempool.update_transaction_proposed(proposed_block)        # Update proposed and confirmed transaction info\n",
    "            # print(f\"[{current_time:.4f}], Mempool updates transactions' proposed information after proposing block at Slot {slot_no}\")\n",
    "            logger.debug(f\"[{current_time:.4f}], Mempool updates transactions' proposed information after proposing block at Slot {slot_no}\")\n",
    "            logger.debug(f\"[{current_time:.4f}], Mempool updates transactions' comfirmed information in advance after proposing block at Slot {slot_no}\")\n",
    "\n",
    "            # Add the proposed block to the list of all candidate blocks (for empty blocks as well)\n",
    "            if proposed_block not in self.model.all_candidate_blocks:\n",
    "                self.model.all_candidate_blocks.append(proposed_block) \n",
    "                logger.debug(f\"[{current_time:.4f}], Proposer generates EMPTY block {proposed_block.block_id} at Slot {slot_no}\")\n",
    "                \n",
    "            self.proposer.update_local_blockchain(proposed_block)           # Update local blockchain in proposer\n",
    "            # print(f\"[{current_time:.4f}], Proposer updates local blockchain after proposing block at Slot {slot_no}\")\n",
    "            logger.debug(f\"[{current_time:.4f}], Proposer updates local blockchain after proposing block at Slot {slot_no}\")\n",
    "            \n",
    "            for builder in self.builders:\n",
    "                # builder.update_seen_transactions(proposed_block)\n",
    "                # # print(f\"[{current_time:.4f}], Builder {builder.builder_id} updates seen transactions after proposing block at Slot {slot_no}\")\n",
    "                # logger.debug(f\"[{current_time:.4f}], Builder {builder.builder_id} updates seen transactions after proposing block at Slot {slot_no}\")\n",
    "                \n",
    "                builder.local_blockchain = self.proposer.local_blockchain.copy()\n",
    "                # print(f\"[{current_time:.4f}], Builder {builder.builder_id} updates local blockchain after proposing block at Slot {slot_no}\")\n",
    "                logger.debug(f\"[{current_time:.4f}], Builder {builder.builder_id} updates local blockchain after proposing block at Slot {slot_no}\")\n",
    "            \n",
    "            for relay in self.relays:\n",
    "                relay.clear_received_ready_blocks()\n",
    "            # print(f\"[{current_time:.4f}], Relay clears old blocks at Slot {slot_no}\")\n",
    "            logger.debug(f\"[{current_time:.4f}], Relay clears old blocks at Slot {slot_no}\")\n",
    "        \n",
    "        elif slot_no == 0:\n",
    "            # Slot 0: no block yet is acceptable\n",
    "            logger.warning(f\"[{current_time:.4f}], Slot {slot_no}, no block available yet, which is expected.\")\n",
    "        else:\n",
    "            # Any other slot should have a proposed block\n",
    "            logger.critical(f\"[{current_time:.4f}], Critical: Proposer has no block at Slot {slot_no}\")\n",
    "            raise RuntimeError(f\"[{current_time:.4f}], Proposer has no block to propose at Slot {slot_no}\")\n",
    "\n",
    "\n",
    "        # Schedule the next SlotStartEvent\n",
    "        self.next_event = current_time + self.interval\n",
    "        self.model.schedule_event(self.next_event, self.event)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        proposer,\n",
    "        mempool,\n",
    "        builders=None,\n",
    "        relays=None,\n",
    "        validators=None,\n",
    "        rng=None,\n",
    "        run_id=0,\n",
    "        stop_time=0,\n",
    "        experiment_name=\"non_censoring\",\n",
    "        experiment_params=None,  \n",
    "        builder_relay_mapping=None,\n",
    "        validator_relay_mapping=None\n",
    "    ):\n",
    "\n",
    "        self.rng = rng or np.random.default_rng()\n",
    "        self.time = 0\n",
    "        self.mempool = mempool\n",
    "        self.proposer = proposer\n",
    "        self.all_candidate_blocks = []          # Store all candidate blocks\n",
    "        self.run_id = run_id\n",
    "        self.stop_time = stop_time\n",
    "        self.experiment_name = experiment_name\n",
    "        self.experiment_params = experiment_params or {}        # Store full experiment parameters\n",
    "        self.event_queue = []                               # Event priority queue: (time, count, function, args)\n",
    "        self.event_count = 0                        # Counter to avoid heap conflicts when times are equal\n",
    "\n",
    "        self.builders = builders\n",
    "        self.relays = relays\n",
    "        self.validators = validators\n",
    "\n",
    "        # Explicitly store builder-relay and validator-relay mappings\n",
    "        self.builder_relay_mapping = builder_relay_mapping\n",
    "        self.validator_relay_mapping = validator_relay_mapping\n",
    "        \n",
    "        logger.info(\"Builder-Relay and Validator-Relay mappings were set externally and remain stable.\")\n",
    "\n",
    "\n",
    "        # # Initialize events\n",
    "        # # Set a fixed offset (can also be randomized using rng.uniform)\n",
    "        # initial_offsets = self.rng.uniform(0, 4, size=len(builders))\n",
    "        # self.builder_events = [\n",
    "        #     BlockBuildingEvent(builder, self, rng=self.rng, offset=initial_offsets[i]) \n",
    "        #     for i, builder in enumerate(self.builders)\n",
    "        # ]\n",
    "\n",
    "        self.builder_events = [BlockBuildingEvent(builder, self, rng=self.rng, offset=5.5)for builder in self.builders]\n",
    "        self.relay_events = [RelayProcessingEvent(relay, self, interval=2, rng=self.rng, offset=10.5) for relay in self.relays]\n",
    "        self.slot_event = SlotStartEvent(proposer, self.builders, self.relays, self.validators, mempool, self.rng, model=self)\n",
    "        \n",
    "        # Event list\n",
    "        # self.events = [self.transaction_event, self.slot_event] + self.builder_events + self.relay_events\n",
    "        self.events = [self.slot_event] + self.builder_events + self.relay_events\n",
    "\n",
    "        # Register all initial events in the scheduler\n",
    "        for event in self.events:\n",
    "            self.schedule_event(event.next_event, event.event)\n",
    "\n",
    "\n",
    "    # Centralized event scheduler for discrete-event simulation\n",
    "    def schedule_event(self, event_time, func, *args):\n",
    "        heapq.heappush(self.event_queue, (event_time, self.event_count, func, args))\n",
    "        self.event_count += 1\n",
    "\n",
    "\n",
    "    # Save all transaction records to CSV\n",
    "    def save_transactions_to_csv(self, filename_prefix=\"transactions\"):\n",
    "        folder = self.experiment_params[\"result_folder\"]\n",
    "        filename = os.path.join(folder, f\"{filename_prefix}.csv\")\n",
    "\n",
    "        all_transactions = list(self.mempool.proposed_transactions.values()) + list(self.mempool.pending_transactions.values())\n",
    "\n",
    "        tx_data = [{\n",
    "            # \"num_builders\": self.experiment_params.get(\"num_builders\"),\n",
    "            # \"num_relays\": self.experiment_params.get(\"num_relays\"),\n",
    "            # \"num_validators\": self.experiment_params.get(\"num_validators\"),\n",
    "            # \"builder_censorship_ratio\": self.experiment_params.get(\"builder_censorship_ratio\"),\n",
    "            # \"strict_builder_ratio\": self.experiment_params.get(\"strict_builder_ratio\"),\n",
    "            # \"relay_censorship_ratio\": self.experiment_params.get(\"relay_censorship_ratio\"),\n",
    "            # \"validator_censorship_ratio\": self.experiment_params.get(\"validator_censorship_ratio\"),\n",
    "            # \"base_block_build_time\": self.experiment_params.get(\"base_block_build_time\"),\n",
    "            # \"base_relay_process_time\": self.experiment_params.get(\"base_relay_process_time\"),\n",
    "            # \"avg_relays_per_builder\": self.experiment_params.get(\"avg_relays_per_builder\"), \n",
    "            # \"censoring_builder_relay_ratio\": self.experiment_params.get(\"censoring_builder_relay_ratio\"),\n",
    "            # \"avg_relays_per_validator\": self.experiment_params.get(\"avg_relays_per_validator\"), \n",
    "            # \"censoring_validator_relay_ratio_non_censoring\":self.experiment_params.get(\"censoring_validator_relay_ratio_non_censoring\"),\n",
    "            # \"builder_skip_probability\": self.experiment_params.get(\"builder_skip_probability\"),\n",
    "            # \"builder_review_time_per_tx\": self.experiment_params.get(\"builder_review_time_per_tx\"),\n",
    "            # \"relay_review_time_per_tx\": self.experiment_params.get(\"relay_review_time_per_tx\"),\n",
    "            # \"type_1_rejection_prob_builder\": self.experiment_params.get(\"type_1_rejection_prob_builder\"),\n",
    "            # \"type_1_rejection_prob_relay\": self.experiment_params.get(\"type_1_rejection_prob_relay\"),\n",
    "            # \"weak_detection_prob\": self.experiment_params.get(\"weak_detection_prob\"),\n",
    "            # \"proposer_reward_ratio\": self.experiment_params.get(\"proposer_reward_ratio\"),\n",
    "            # \"tx_rate\": self.experiment_params.get(\"tx_rate\"),\n",
    "            # \"sanctioned_probs\": self.experiment_params.get(\"sanctioned_probs\"),\n",
    "            # \"stop_time\": self.stop_time,\n",
    "            \"run_id\": self.run_id,                        \n",
    "            \"tx_id\": tx.tx_id,\n",
    "            \"arrival_time\": tx.arrival_time,\n",
    "            \"transaction_type\": tx.transaction_type,\n",
    "            \"sanctioned_type\": tx.sanctioned_type,\n",
    "            \"gas_used\": tx.gas_used,\n",
    "            \"base_fee_per_gas\": tx.base_fee_per_gas,\n",
    "            \"priority_fee_per_gas\": tx.priority_fee_per_gas,\n",
    "            \"priority_fee\": tx.priority_fee,\n",
    "            \"gas_fee\": tx.gas_fee,\n",
    "            \"proposed_block_id\": tx.proposed_block_id,\n",
    "            \"proposed_builder_id\": tx.proposed_builder_id,\n",
    "            \"proposed_builder_policy\": tx.proposed_builder_policy,\n",
    "            \"selected_relay_id\": tx.selected_relay_id,\n",
    "            \"selected_relay_policy\": tx.selected_relay_policy,\n",
    "            \"proposer_validator_id\": tx.proposer_validator_id,  \n",
    "            \"proposer_validator_is_censoring\": tx.proposer_validator_is_censoring,  \n",
    "            \"proposed_time\": tx.proposed_time,\n",
    "            \"confirmed_time\": tx.confirmed_time,\n",
    "            \"is_proposed\": tx.is_proposed,\n",
    "            \"is_confirmed\": tx.is_confirmed,           \n",
    "        } for tx in all_transactions]\n",
    "\n",
    "        df_tx = pd.DataFrame(tx_data)\n",
    "\n",
    "        # Append mode: append if file exists, otherwise create\n",
    "        if os.path.exists(filename):\n",
    "            df_tx.to_csv(filename, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            df_tx.to_csv(filename, mode='w', header=True, index=False)\n",
    "\n",
    "        # print(f\"All transaction data appended to {os.path.abspath(filename)}\")\n",
    "        logger.info(f\"All transaction data appended to {os.path.abspath(filename)}\")\n",
    "\n",
    "\n",
    "    # Save all block records to CSV\n",
    "    def save_blocks_to_csv(self, filename_prefix=\"blocks\"):\n",
    "        folder = self.experiment_params[\"result_folder\"]\n",
    "        filename = os.path.join(folder, f\"{filename_prefix}.csv\")\n",
    "\n",
    "        blocks_data = [{\n",
    "            # \"num_builders\": self.experiment_params.get(\"num_builders\"),\n",
    "            # \"num_relays\": self.experiment_params.get(\"num_relays\"),\n",
    "            # \"num_validators\": self.experiment_params.get(\"num_validators\"),\n",
    "            # \"builder_censorship_ratio\": self.experiment_params.get(\"builder_censorship_ratio\"),\n",
    "            # \"strict_builder_ratio\": self.experiment_params.get(\"strict_builder_ratio\"),\n",
    "            # \"relay_censorship_ratio\": self.experiment_params.get(\"relay_censorship_ratio\"),\n",
    "            # \"validator_censorship_ratio\": self.experiment_params.get(\"validator_censorship_ratio\"),\n",
    "            # \"base_block_build_time\": self.experiment_params.get(\"base_block_build_time\"),\n",
    "            # \"base_relay_process_time\": self.experiment_params.get(\"base_relay_process_time\"),\n",
    "            # \"avg_relays_per_builder\": self.experiment_params.get(\"avg_relays_per_builder\"), \n",
    "            # \"censoring_builder_relay_ratio\": self.experiment_params.get(\"censoring_builder_relay_ratio\"),\n",
    "            # \"avg_relays_per_validator\": self.experiment_params.get(\"avg_relays_per_validator\"), \n",
    "            # \"censoring_validator_relay_ratio_non_censoring\":self.experiment_params.get(\"censoring_validator_relay_ratio_non_censoring\"),\n",
    "            # \"builder_skip_probability\": self.experiment_params.get(\"builder_skip_probability\"),\n",
    "            # \"builder_review_time_per_tx\": self.experiment_params.get(\"builder_review_time_per_tx\"),\n",
    "            # \"relay_review_time_per_tx\": self.experiment_params.get(\"relay_review_time_per_tx\"),\n",
    "            # \"type_1_rejection_prob_builder\": self.experiment_params.get(\"type_1_rejection_prob_builder\"),\n",
    "            # \"type_1_rejection_prob_relay\": self.experiment_params.get(\"type_1_rejection_prob_relay\"),\n",
    "            # \"weak_detection_prob\": self.experiment_params.get(\"weak_detection_prob\"),\n",
    "            # \"proposer_reward_ratio\": self.experiment_params.get(\"proposer_reward_ratio\"),\n",
    "            # \"tx_rate\": self.experiment_params.get(\"tx_rate\"),\n",
    "            # \"sanctioned_probs\": self.experiment_params.get(\"sanctioned_probs\"),\n",
    "            # \"stop_time\": self.stop_time,\n",
    "            \"run_id\": self.run_id,                    \n",
    "            \"block_id\": block.block_id,\n",
    "            \"builder_id\": block.builder_id,\n",
    "            \"builder_policy\": block.builder_policy,\n",
    "            \"slot_no\": block.slot_no,\n",
    "            \"parent_block_id\": block.parent_block_id,\n",
    "            \"num_transactions\": block.num_transactions,\n",
    "            \"num_non_sanctioned_tx\": block.tx_counts.get(0, 0),  \n",
    "            \"num_sanctioned_tx\": block.tx_counts.get(1, 0),  \n",
    "            \"total_gas_used\": block.total_gas_used,\n",
    "            \"total_gas_fee\": block.total_gas_fee,\n",
    "            \"total_priority_fee\": block.total_priority_fee,\n",
    "            \"proposed_time\": block.proposed_time,\n",
    "            \"confirmed_time\": block.confirmed_time,\n",
    "            \"builder_review_time\": block.builder_review_time,\n",
    "            \"relay_reject_count\": block.relay_reject_count,\n",
    "            \"proposer_reject_count\": block.proposer_reject_count,\n",
    "            \"is_relay_approved\": block.is_relay_approved,\n",
    "            \"is_proposed\": block.is_proposed,\n",
    "            \"is_confirmed\": block.is_confirmed,\n",
    "            \"selected_relay_id\": block.selected_relay_id,\n",
    "            \"selected_relay_policy\": block.selected_relay_policy,\n",
    "            \"proposer_validator_id\": block.proposer_validator_id,  \n",
    "            \"proposer_validator_is_censoring\": block.proposer_validator_is_censoring,  \n",
    "            \"builder_profit\": block.builder_profit,\n",
    "            \"proposer_profit\": block.proposer_profit\n",
    "        } for block in self.all_candidate_blocks]\n",
    "\n",
    "        df_blocks = pd.DataFrame(blocks_data)\n",
    "\n",
    "        # Append mode: append if file exists, otherwise create\n",
    "        if os.path.exists(filename):\n",
    "            df_blocks.to_csv(filename, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            df_blocks.to_csv(filename, mode='w', header=True, index=False)\n",
    "        \n",
    "        # print(f\"All candidate blocks data saved to {os.path.abspath(filename)}\")\n",
    "        logger.info(f\"All candidate blocks data saved to {os.path.abspath(filename)}\")\n",
    "\n",
    "\n",
    "    def run(self, stop_time, max_event_count=None):\n",
    "        \"\"\"\n",
    "        Run the simulation until stop_time or until max_event_count is reached.\n",
    "        This prevents infinite loops.\n",
    "        \"\"\"\n",
    "        event_counter = 0                   # Track how many events have been processed\n",
    "        while self.event_queue and self.time < stop_time:\n",
    "            event_time, _, event_callable, args = heapq.heappop(self.event_queue)\n",
    "            \n",
    "            # # Check if the event time is in the future\n",
    "            # future_event_times = [et[0] for et in self.event_queue]\n",
    "            # if future_event_times and future_event_times[0] < event_time:\n",
    "            #     raise RuntimeError(\n",
    "            #         f\"[Event Queue Error] Next event time={future_event_times[0]:.4f} < current event time={event_time:.4f}\"\n",
    "            #     )\n",
    "\n",
    "            if event_time >= stop_time:\n",
    "                # print(f\"No events left before stop_time={stop_time}. Ending simulation at time={self.time:.4f}\")\n",
    "                logger.info(f\"No events left before stop_time={stop_time}. Ending simulation at time={self.time:.4f}\")\n",
    "                break\n",
    "\n",
    "            self.time = event_time\n",
    "            \n",
    "            # Trigger the scheduled event\n",
    "            event_callable(*args)\n",
    "            event_counter += 1\n",
    "\n",
    "            if max_event_count is not None and event_counter >= max_event_count:\n",
    "                # print(f\"Reached max_event_count={max_event_count}. Stopping simulation at time={self.time:.4f}\")\n",
    "                logger.critical(f\"Reached max_event_count={max_event_count}. Stopping at time={self.time:.4f}\")\n",
    "                break\n",
    "        \n",
    "        # Save results after simulation ends\n",
    "        self.save_transactions_to_csv()\n",
    "        self.save_blocks_to_csv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentSetup:\n",
    "    def __init__(self, rng):\n",
    "        self.rng = rng\n",
    "\n",
    "    def initialize_agents(\n",
    "        self,\n",
    "        num_builders=20,\n",
    "        num_relays=10,\n",
    "        num_validators=10,\n",
    "        builder_censorship_ratio=0.0,\n",
    "        strict_builder_ratio=0.0,               # Proportion of strict builders among censoring builders\n",
    "        relay_censorship_ratio=0.0,\n",
    "        validator_censorship_ratio=0.0,\n",
    "        base_block_build_time=4.0,\n",
    "        base_relay_process_time=1.0,\n",
    "        builder_skip_probability=0.1,\n",
    "        builder_review_time_per_tx=0.00315,\n",
    "        relay_review_time_per_tx=0.00315,\n",
    "        type_1_rejection_prob_builder=1.0,\n",
    "        type_1_rejection_prob_relay=1.0,\n",
    "        weak_detection_prob=1.0,\n",
    "        proposer_reward_ratio=0.95\n",
    "    ):\n",
    "        num_censoring_builders = int(num_builders * builder_censorship_ratio)\n",
    "        num_strict = int(num_censoring_builders * strict_builder_ratio)\n",
    "\n",
    "        builders = []\n",
    "        for i in range(num_builders):\n",
    "            if i < num_strict:\n",
    "                policy = \"strict\"\n",
    "            elif i < num_censoring_builders:\n",
    "                policy = \"weak\"\n",
    "            else:\n",
    "                policy = \"non\"\n",
    "            \n",
    "            is_censoring = policy in [\"weak\", \"strict\"]\n",
    "\n",
    "            builder = Builder(\n",
    "                mempool=None,\n",
    "                rng=self.rng,\n",
    "                builder_id=i,\n",
    "                censorship_policy=CensorshipPolicy(\n",
    "                    builder_policy=policy,\n",
    "                    relay_policy=\"non\",\n",
    "                    type_1_rejection_prob_builder=type_1_rejection_prob_builder,\n",
    "                    builder_review_time_per_tx=builder_review_time_per_tx,\n",
    "                    weak_detection_prob=weak_detection_prob,\n",
    "                    rng=self.rng\n",
    "                ),\n",
    "                relays=[],\n",
    "                is_censoring=is_censoring,\n",
    "                base_block_build_time=base_block_build_time,\n",
    "                skip_probability=builder_skip_probability,\n",
    "                proposer_reward_ratio=proposer_reward_ratio,\n",
    "            )\n",
    "\n",
    "            builders.append(builder)\n",
    "\n",
    "\n",
    "        num_censoring_relays = int(num_relays * relay_censorship_ratio)\n",
    "        relays = [\n",
    "            Relay(\n",
    "                relay_id=i,\n",
    "                censorship_policy=CensorshipPolicy(\n",
    "                    builder_policy=\"non\",\n",
    "                    relay_policy=\"censoring\" if i < num_censoring_relays else \"non\",\n",
    "                    type_1_rejection_prob_relay=type_1_rejection_prob_relay,\n",
    "                    relay_review_time_per_tx=relay_review_time_per_tx,\n",
    "                    rng=self.rng\n",
    "                ),\n",
    "                is_censoring=(i < num_censoring_relays),\n",
    "                base_relay_process_time=base_relay_process_time\n",
    "            ) for i in range(num_relays)\n",
    "        ]\n",
    "\n",
    "\n",
    "        num_censoring_validators = int(num_validators * validator_censorship_ratio)\n",
    "        validators = [\n",
    "            Validator(\n",
    "                validator_id=i,\n",
    "                connected_relays=[],\n",
    "                is_censoring=(i < num_censoring_validators)\n",
    "            ) for i in range(num_validators)\n",
    "        ]\n",
    "\n",
    "        return builders, relays, validators\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    censoring_builder_relay_ratio = 0.75\n",
    "    - Censoring builders connect to: 75% censoring relays + 25% non-censoring relays\n",
    "    - Non-censoring builders connect to: 75% non-censoring relays + 25% censoring relays\n",
    "    \"\"\"\n",
    "\n",
    "    def construct_builder_relay_mapping(\n",
    "        self,\n",
    "        builders,\n",
    "        relays,\n",
    "        avg_relays_per_builder=4,\n",
    "        censoring_builder_relay_ratio=0.75\n",
    "    ):\n",
    "        builder_relay_mapping = {}\n",
    "\n",
    "        censoring_relays = [r for r in relays if r.is_censoring]\n",
    "        non_censoring_relays = [r for r in relays if not r.is_censoring]\n",
    "\n",
    "        # Step 1: Ensure each relay is connected to at least one builder\n",
    "        for relay in relays:\n",
    "            possible_builders = [b for b in builders if relay.is_censoring == b.is_censoring]\n",
    "            if not possible_builders:\n",
    "                possible_builders = builders                # If no matching type, allow cross-type connection\n",
    "            chosen_builder = self.rng.choice(possible_builders)\n",
    "            chosen_builder.relays.append(relay)\n",
    "\n",
    "        # Step 2: Then fill in remaining connections according to ratio\n",
    "        for builder in builders:\n",
    "            current_relays = set(builder.relays)\n",
    "            remaining_relays_needed = max(0, avg_relays_per_builder - len(current_relays))\n",
    "\n",
    "            if remaining_relays_needed > 0:\n",
    "                if builder.is_censoring:\n",
    "                    num_censoring = max(1, int(remaining_relays_needed * censoring_builder_relay_ratio)) if censoring_relays else 0\n",
    "                    num_non_censoring = remaining_relays_needed - num_censoring\n",
    "                else:\n",
    "                    num_non_censoring = max(1, int(remaining_relays_needed * censoring_builder_relay_ratio)) if non_censoring_relays else 0\n",
    "                    num_censoring = remaining_relays_needed - num_non_censoring\n",
    "\n",
    "                # If either group is empty, select all from the other group\n",
    "                if not censoring_relays:\n",
    "                    num_non_censoring = remaining_relays_needed\n",
    "                    num_censoring = 0\n",
    "                if not non_censoring_relays:\n",
    "                    num_censoring = remaining_relays_needed\n",
    "                    num_non_censoring = 0\n",
    "\n",
    "\n",
    "                available_censoring_relays = [r for r in censoring_relays if r not in current_relays]\n",
    "                available_non_censoring_relays = [r for r in non_censoring_relays if r not in current_relays]\n",
    "\n",
    "                selected_censoring = self.rng.choice(\n",
    "                    available_censoring_relays, \n",
    "                    size=min(num_censoring, len(available_censoring_relays)), \n",
    "                    replace=False\n",
    "                ).tolist()\n",
    "\n",
    "                selected_non_censoring = self.rng.choice(\n",
    "                    available_non_censoring_relays, \n",
    "                    size=min(num_non_censoring, len(available_non_censoring_relays)), \n",
    "                    replace=False\n",
    "                ).tolist()\n",
    "\n",
    "                selected_relays = selected_censoring + selected_non_censoring\n",
    "                builder.relays.extend(selected_relays)\n",
    "\n",
    "            builder_relay_mapping[builder.builder_id] = [relay.relay_id for relay in builder.relays]\n",
    "\n",
    "        return builder_relay_mapping\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    - Censoring validators (e.g. 20%) connect only to censoring relays (censoring_validator_relay_ratio = 1)\n",
    "    - Non-censoring validators (e.g. 80%) connect to 75% non-censoring relays + 25% censoring relays (censoring_validator_relay_ratio = 0.25)\n",
    "    \"\"\"\n",
    "\n",
    "    def construct_validator_relay_mapping(\n",
    "        self,\n",
    "        validators,\n",
    "        relays,\n",
    "        avg_relays_per_validator=4,\n",
    "        censoring_validator_relay_ratio_censoring=1.0,          # For clarity only; not directly used\n",
    "        censoring_validator_relay_ratio_non_censoring=0.25      # Ratio for non-censoring validators connecting to censoring relays\n",
    "    ):\n",
    "        validator_relay_mapping = {}\n",
    "\n",
    "        censoring_relays = [r for r in relays if r.is_censoring]\n",
    "        non_censoring_relays = [r for r in relays if not r.is_censoring]\n",
    "\n",
    "        # Step 1: Ensure each relay is connected to at least one validator\n",
    "        for relay in relays:\n",
    "            possible_validators = [v for v in validators if relay.is_censoring == v.is_censoring]\n",
    "            if not possible_validators:\n",
    "                possible_validators = validators\n",
    "            chosen_validator = self.rng.choice(possible_validators)\n",
    "            chosen_validator.connected_relays.append(relay)\n",
    "\n",
    "        # Step 2: Fill remaining connections for each validator\n",
    "        for validator in validators:\n",
    "            current_relays = set(validator.connected_relays)\n",
    "            remaining_relays_needed = max(0, avg_relays_per_validator - len(current_relays))\n",
    "\n",
    "            if remaining_relays_needed > 0:\n",
    "                if validator.is_censoring:\n",
    "                    if censoring_relays:                    # Censoring validators connect only to censoring relays\n",
    "                        selected_relays = self.rng.choice(\n",
    "                            [r for r in censoring_relays if r not in current_relays],\n",
    "                            size=min(remaining_relays_needed, len([r for r in censoring_relays if r not in current_relays])),\n",
    "                            replace=False\n",
    "                        ).tolist()\n",
    "                    else:                                   # No censoring relays available, select from non-censoring relays\n",
    "                        selected_relays = self.rng.choice(\n",
    "                            [r for r in non_censoring_relays if r not in current_relays],\n",
    "                            size=min(remaining_relays_needed, len([r for r in non_censoring_relays if r not in current_relays])),\n",
    "                            replace=False\n",
    "                        ).tolist()\n",
    "\n",
    "                else:\n",
    "                    if non_censoring_relays and censoring_relays:\n",
    "                        num_censoring = max(1, int(remaining_relays_needed * censoring_validator_relay_ratio_non_censoring))\n",
    "                        num_non_censoring = remaining_relays_needed - num_censoring\n",
    "\n",
    "                        selected_censoring = self.rng.choice(\n",
    "                            [r for r in censoring_relays if r not in current_relays],\n",
    "                            size=min(num_censoring, len([r for r in censoring_relays if r not in current_relays])),\n",
    "                            replace=False\n",
    "                        ).tolist()\n",
    "\n",
    "                        selected_non_censoring = self.rng.choice(\n",
    "                            [r for r in non_censoring_relays if r not in current_relays],\n",
    "                            size=min(num_non_censoring, len([r for r in non_censoring_relays if r not in current_relays])),\n",
    "                            replace=False\n",
    "                        ).tolist()\n",
    "\n",
    "                        selected_relays = selected_censoring + selected_non_censoring\n",
    "                    elif censoring_relays:\n",
    "                        selected_relays = self.rng.choice(\n",
    "                            [r for r in censoring_relays if r not in current_relays],\n",
    "                            size=min(remaining_relays_needed, len(censoring_relays)),\n",
    "                            replace=False\n",
    "                        ).tolist()\n",
    "                    else:\n",
    "                        selected_relays = self.rng.choice(\n",
    "                            [r for r in non_censoring_relays if r not in current_relays],\n",
    "                            size=min(remaining_relays_needed, len(non_censoring_relays)),\n",
    "                            replace=False\n",
    "                        ).tolist()\n",
    "\n",
    "                validator.connected_relays.extend(selected_relays)\n",
    "                \n",
    "            validator_relay_mapping[validator.validator_id] = [relay.relay_id for relay in validator.connected_relays]\n",
    "\n",
    "        return validator_relay_mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(\n",
    "    builders,      # Instances of Builder\n",
    "    relays,          # Instances of Relay\n",
    "    validators,         # Instances of Validator\n",
    "    builder_censorship_ratio,\n",
    "    strict_builder_ratio,\n",
    "    relay_censorship_ratio,\n",
    "    validator_censorship_ratio,\n",
    "    builder_relay_mapping, \n",
    "    validator_relay_mapping,\n",
    "    base_block_build_time,\n",
    "    base_relay_process_time,\n",
    "    avg_relays_per_builder,\n",
    "    censoring_builder_relay_ratio,\n",
    "    avg_relays_per_validator,\n",
    "    censoring_validator_relay_ratio_non_censoring,\n",
    "    builder_skip_probability,\n",
    "    builder_review_time_per_tx,\n",
    "    relay_review_time_per_tx,\n",
    "    type_1_rejection_prob_builder,\n",
    "    type_1_rejection_prob_relay,\n",
    "    weak_detection_prob,\n",
    "    proposer_reward_ratio,\n",
    "    tx_rate=13,\n",
    "    sanctioned_probs=[0.995, 0.005],\n",
    "    rng_seed=None,\n",
    "    run_id=1,\n",
    "    stop_time=3601.1,\n",
    "    max_event_count=10000,\n",
    "    experiment_name=\"non_censoring\",\n",
    "    result_folder=None \n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Run the Ethereum PBS simulation by initializing the 'Model' and executing it for 'stop_time' seconds.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(f\"Result output directory: {result_folder}\")\n",
    "    assert result_folder is not None and os.path.exists(result_folder), \"result_folder does not exist or is not provided!\"\n",
    "\n",
    "    rng = np.random.default_rng(rng_seed)  # Fix the random seed for reproducibility\n",
    "\n",
    "    # Create the mempool\n",
    "    mempool = Mempool(rng, tx_rate, sanctioned_probs=sanctioned_probs)\n",
    "\n",
    "    # Pre-generate all transactions\n",
    "    mempool.generate_transactions(current_time=0, simulation_time=stop_time)\n",
    "\n",
    "    for builder in builders:\n",
    "        builder.mempool = mempool\n",
    "\n",
    "    # Create the Proposer\n",
    "    proposer = Proposer()\n",
    "\n",
    "    # Store all experimental parameters into a dictionary\n",
    "    experiment_params = {\n",
    "        \"num_builders\": len(builders),\n",
    "        \"num_relays\": len(relays),\n",
    "        \"num_validators\": len(validators),\n",
    "        \"builder_censorship_ratio\": builder_censorship_ratio,\n",
    "        \"strict_builder_ratio\": strict_builder_ratio,\n",
    "        \"relay_censorship_ratio\": relay_censorship_ratio,\n",
    "        \"validator_censorship_ratio\": validator_censorship_ratio,\n",
    "        \"builder_relay_mapping\": builder_relay_mapping,      \n",
    "        \"validator_relay_mapping\": validator_relay_mapping,  \n",
    "        \"base_block_build_time\": base_block_build_time,\n",
    "        \"base_relay_process_time\": base_relay_process_time,\n",
    "        \"avg_relays_per_builder\": avg_relays_per_builder,\n",
    "        \"censoring_builder_relay_ratio\": censoring_builder_relay_ratio,\n",
    "        \"avg_relays_per_validator\": avg_relays_per_validator,\n",
    "        \"censoring_validator_relay_ratio_non_censoring\": censoring_validator_relay_ratio_non_censoring,\n",
    "        \"builder_skip_probability\": builder_skip_probability,\n",
    "        \"builder_review_time_per_tx\": builder_review_time_per_tx,\n",
    "        \"relay_review_time_per_tx\": relay_review_time_per_tx,\n",
    "        \"type_1_rejection_prob_builder\": type_1_rejection_prob_builder,\n",
    "        \"type_1_rejection_prob_relay\": type_1_rejection_prob_relay,\n",
    "        \"weak_detection_prob\": weak_detection_prob,\n",
    "        \"proposer_reward_ratio\": proposer_reward_ratio,\n",
    "        \"tx_rate\": tx_rate,\n",
    "        \"sanctioned_probs\": sanctioned_probs,\n",
    "        \"result_folder\": result_folder,\n",
    "        \"rng_seed\": rng_seed,\n",
    "        \"run_id\": run_id,\n",
    "        \"stop_time\": stop_time,\n",
    "        \"max_event_count\": max_event_count,\n",
    "        \"experiment_name\": experiment_name\n",
    "    }\n",
    "\n",
    "    # Initialize the simulation model\n",
    "    model = Model(\n",
    "        proposer=proposer,\n",
    "        mempool=mempool,\n",
    "        builders=builders,\n",
    "        relays=relays,\n",
    "        validators=validators,\n",
    "        rng=rng,\n",
    "        run_id=run_id,\n",
    "        stop_time=stop_time,\n",
    "        experiment_name=experiment_name,\n",
    "        experiment_params=experiment_params,\n",
    "        builder_relay_mapping=builder_relay_mapping,\n",
    "        validator_relay_mapping=validator_relay_mapping\n",
    "    )\n",
    "\n",
    "\n",
    "    # print(f\"Simulation starts: run_id={run_id}, type={experiment_name}\")\n",
    "    # print(f\"Simulation starts with transaction sanctioned_probs={sanctioned_probs}, {num_builders} Builders ({builder_censorship_ratio*100:.0f}% {builder_policy} censoring), \"\n",
    "    #       f\"{num_relays} Relays ({relay_censorship_ratio*100:.0f}% {relay_policy} censoring), \"\n",
    "    #       f\"avg_relays_per_builder={avg_relays_per_builder}, tx_rate={tx_rate}/s, duration={stop_time}s.\")\n",
    "    \n",
    "    logger.info(f\"Simulation starts: run_id={run_id}, experiment_name={experiment_name}.\")\n",
    "    \n",
    "    # Run the simulation\n",
    "    model.run(stop_time, max_event_count=max_event_count)\n",
    "\n",
    "    # print(\"Simulation finished.\")\n",
    "    logger.info(f\"Simulation finished: run_id={run_id}.\")\n",
    "\n",
    "    \n",
    "    return experiment_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_params(params_dict, folder, filename_prefix=\"experiment_params.json\"):\n",
    "    \"\"\"\n",
    "    Save experiment parameters to a JSON file located in the result directory.\n",
    "    \"\"\"\n",
    "    # tx_rate = params_dict[\"tx_rate\"]\n",
    "    # filename = f\"{filename_prefix}_run_{tx_rate}.json\"\n",
    "    file_path = os.path.join(folder, filename_prefix)\n",
    "    \n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(params_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    logger.info(f\"Experiment parameters saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulations Progress: relay_censorship_ratio_0.000: 100%|██████████| 10/10 [13:33<00:00, 81.32s/it]\n",
      "Simulations Progress: relay_censorship_ratio_0.100: 100%|██████████| 10/10 [12:26<00:00, 74.62s/it]\n",
      "Simulations Progress: relay_censorship_ratio_0.200: 100%|██████████| 10/10 [12:09<00:00, 72.98s/it]\n",
      "Simulations Progress: relay_censorship_ratio_0.300: 100%|██████████| 10/10 [12:34<00:00, 75.41s/it]\n",
      "Simulations Progress: relay_censorship_ratio_0.400: 100%|██████████| 10/10 [12:13<00:00, 73.39s/it]\n",
      "Simulations Progress: relay_censorship_ratio_0.500: 100%|██████████| 10/10 [11:25<00:00, 68.58s/it]\n",
      "Simulations Progress: relay_censorship_ratio_0.600: 100%|██████████| 10/10 [10:01<00:00, 60.15s/it]\n",
      "Simulations Progress: relay_censorship_ratio_0.700: 100%|██████████| 10/10 [12:02<00:00, 72.30s/it]\n",
      "Simulations Progress: relay_censorship_ratio_0.800: 100%|██████████| 10/10 [14:12<00:00, 85.25s/it]\n",
      "Simulations Progress: relay_censorship_ratio_0.900: 100%|██████████| 10/10 [12:32<00:00, 75.25s/it]\n",
      "Simulations Progress: relay_censorship_ratio_1.000: 100%|██████████| 10/10 [20:55<00:00, 125.51s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define baseline model parameters\n",
    "params = {\n",
    "    \"num_builders\": 20,\n",
    "    \"num_relays\": 10,\n",
    "    \"num_validators\": 10,\n",
    "    \"builder_censorship_ratio\": 0.5,\n",
    "    \"strict_builder_ratio\": 0.5,         \n",
    "    \"relay_censorship_ratio\": 0.5,\n",
    "    \"validator_censorship_ratio\": 0.2,\n",
    "    \"base_block_build_time\": 4.0,\n",
    "    \"base_relay_process_time\": 1.0,\n",
    "    \"avg_relays_per_builder\": 4,\n",
    "    \"censoring_builder_relay_ratio\": 0.75,\n",
    "    \"avg_relays_per_validator\": 4,\n",
    "    \"censoring_validator_relay_ratio_non_censoring\": 0.25,\n",
    "    \"builder_skip_probability\": 0.1,\n",
    "    \"builder_review_time_per_tx\": 0.00315,\n",
    "    \"relay_review_time_per_tx\": 0.00315,\n",
    "    \"type_1_rejection_prob_builder\": 1.0,\n",
    "    \"type_1_rejection_prob_relay\": 1.0,\n",
    "    \"weak_detection_prob\": 1.0,\n",
    "    \"proposer_reward_ratio\": 0.95,\n",
    "    \"tx_rate\": 13,\n",
    "    \"sanctioned_probs\": [0.995, 0.005]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize base random seed\n",
    "base_seed = 10\n",
    "\n",
    "# builder_review_times_per_tx = np.linspace(0.000, 0.01, 11)\n",
    "builder_review_times_per_tx = [0.000, 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.010, \n",
    "                               0.015, 0.020, 0.025, 0.030, 0.035, 0.040, 0.045, 0.050, 0.060, 0.070, 0.080, 0.090, 0.100]\n",
    "\n",
    "# relay_censorship_ratios = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for builder_review_time_per_tx in builder_review_times_per_tx:\n",
    "    # Create a subfolder for each experiment\n",
    "    date_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    experiment_name = f\"builder_review_time_per_tx_{builder_review_time_per_tx:.3f}_{date_str}\"\n",
    "    \n",
    "    # Store results under the main result folder\n",
    "    result_folder = os.path.join(main_result_folder, experiment_name)\n",
    "    os.makedirs(result_folder, exist_ok=True)\n",
    "\n",
    "    # # Dynamically update logger handler (commented out to disable file logging)\n",
    "    # for handler in logger.handlers[:]:\n",
    "    #     logger.removeHandler(handler)\n",
    "\n",
    "    # log_filename = os.path.join(result_folder, 'simulation.log')\n",
    "    # file_handler = logging.FileHandler(log_filename, mode='w', encoding='utf-8')\n",
    "    # file_handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s [%(name)s]: %(message)s'))\n",
    "    # logger.addHandler(file_handler)\n",
    "\n",
    "    # logger.info(f\"Simulation started. Results are saved to {result_folder}\")\n",
    "\n",
    "\n",
    "    # Run simulation\n",
    "    for run_id in tqdm(range(1, 11), desc=f\"Simulations Progress: builder_review_time_per_tx_{builder_review_time_per_tx:.3f}\"): \n",
    "        \n",
    "        # Ensure consistent agent initialization and mapping for each run  \n",
    "        # Set up random number generator\n",
    "        rng = np.random.default_rng(base_seed)\n",
    "\n",
    "        # Instantiate AgentSetup\n",
    "        agent_setup = AgentSetup(rng)\n",
    "\n",
    "        # Update the parameter\n",
    "        params[\"builder_review_time_per_tx\"] = builder_review_time_per_tx\n",
    "\n",
    "        # Remove parameters not needed by the simulate function\n",
    "        params_for_simulate = params.copy()\n",
    "        params_for_simulate.pop('num_builders')\n",
    "        params_for_simulate.pop('num_relays')\n",
    "        params_for_simulate.pop('num_validators')\n",
    "\n",
    "        # Initialize all agents\n",
    "        builders, relays, validators = agent_setup.initialize_agents(\n",
    "            num_builders=params[\"num_builders\"],\n",
    "            num_relays=params[\"num_relays\"],\n",
    "            num_validators=params[\"num_validators\"],\n",
    "            builder_censorship_ratio=params[\"builder_censorship_ratio\"],\n",
    "            strict_builder_ratio=params[\"strict_builder_ratio\"],   \n",
    "            relay_censorship_ratio=params[\"relay_censorship_ratio\"],\n",
    "            validator_censorship_ratio=params[\"validator_censorship_ratio\"],\n",
    "            base_block_build_time=params[\"base_block_build_time\"],       \n",
    "            base_relay_process_time=params[\"base_relay_process_time\"],\n",
    "            builder_skip_probability=params[\"builder_skip_probability\"],\n",
    "            builder_review_time_per_tx=params[\"builder_review_time_per_tx\"],\n",
    "            relay_review_time_per_tx=params[\"relay_review_time_per_tx\"],\n",
    "            type_1_rejection_prob_builder=params[\"type_1_rejection_prob_builder\"],\n",
    "            type_1_rejection_prob_relay=params[\"type_1_rejection_prob_relay\"],\n",
    "            weak_detection_prob=params[\"weak_detection_prob\"],\n",
    "            proposer_reward_ratio=params[\"proposer_reward_ratio\"]\n",
    "        )\n",
    "\n",
    "        # Construct and retrieve connection mappings\n",
    "        builder_relay_mapping = agent_setup.construct_builder_relay_mapping(\n",
    "            builders=builders,\n",
    "            relays=relays,\n",
    "            avg_relays_per_builder=params[\"avg_relays_per_builder\"],                \n",
    "            censoring_builder_relay_ratio=params[\"censoring_builder_relay_ratio\"]\n",
    "        )\n",
    "\n",
    "        validator_relay_mapping = agent_setup.construct_validator_relay_mapping(\n",
    "            validators=validators,\n",
    "            relays=relays,\n",
    "            avg_relays_per_validator=params[\"avg_relays_per_validator\"],      \n",
    "            censoring_validator_relay_ratio_censoring=1.0,                    \n",
    "            censoring_validator_relay_ratio_non_censoring=params[\"censoring_validator_relay_ratio_non_censoring\"]     \n",
    "        )\n",
    "\n",
    "        # Run simulation\n",
    "        experiment_params = simulate(\n",
    "            builders=builders,\n",
    "            relays=relays,\n",
    "            validators=validators,\n",
    "            builder_relay_mapping=builder_relay_mapping,\n",
    "            validator_relay_mapping=validator_relay_mapping,\n",
    "            **params_for_simulate,           # Use the cleaned parameter dictionary\n",
    "            rng_seed=base_seed + run_id, \n",
    "            run_id=run_id,\n",
    "            stop_time=3601.1,\n",
    "            max_event_count=None,\n",
    "            experiment_name=experiment_name,\n",
    "            result_folder=result_folder         # Save results to the specific subfolder\n",
    "        )\n",
    "\n",
    "        # Save simulation output directly\n",
    "        save_experiment_params(experiment_params, result_folder)\n",
    "\n",
    "    logger.info(f\"Completed simulation for builder_review_time_per_tx = {builder_review_time_per_tx:.3f}\")\n",
    "\n",
    "    # # Clean up logger handler (commented out to disable file logging)\n",
    "    # logger.removeHandler(file_handler)\n",
    "    # file_handler.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_simulation_parallel(params_tuple):\n",
    "#     builder_time, relay_time, run_id, result_folder = params_tuple\n",
    "    \n",
    "#     # Explicitly disable default subprocess terminal output and avoid extra log files\n",
    "#     logging.getLogger().handlers.clear()\n",
    "#     logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "#     # # Dynamically add logger handler (disabled: no longer writing log files)\n",
    "#     # file_handler = logging.FileHandler(os.path.join(result_folder, 'simulation.log'), mode='a', encoding='utf-8')\n",
    "#     # file_handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s [%(name)s]: %(message)s'))\n",
    "    \n",
    "#     # logger.handlers.clear()\n",
    "#     # logger.addHandler(file_handler)\n",
    "    \n",
    "#     logger = logging.getLogger(\"EthereumPBS\")\n",
    "#     logger.setLevel(logging.CRITICAL)\n",
    "    \n",
    "#     logger.info(f\"Simulation started. Results are saved to {result_folder}\")\n",
    "\n",
    "#     # RNG for mapping (shared seed)\n",
    "#     mapping_rng_seed = 10\n",
    "#     mapping_rng = np.random.default_rng(mapping_rng_seed)\n",
    "#     agent_setup = AgentSetup(mapping_rng)\n",
    "\n",
    "#     # Separate RNG for each simulation run\n",
    "#     simulation_rng_seed = mapping_rng_seed + run_id\n",
    "\n",
    "#     # Deep copy of params to fully isolate for each thread/process\n",
    "#     local_params = copy.deepcopy(params)  \n",
    "#     local_params[\"builder_review_time_per_tx\"] = builder_time\n",
    "#     local_params[\"relay_review_time_per_tx\"] = relay_time\n",
    "\n",
    "#     builders, relays, validators = agent_setup.initialize_agents(\n",
    "#         num_builders=local_params[\"num_builders\"],\n",
    "#         num_relays=local_params[\"num_relays\"],\n",
    "#         num_validators=local_params[\"num_validators\"],\n",
    "#         builder_censorship_ratio=local_params[\"builder_censorship_ratio\"],\n",
    "#         strict_builder_ratio=local_params[\"strict_builder_ratio\"],\n",
    "#         relay_censorship_ratio=local_params[\"relay_censorship_ratio\"],\n",
    "#         validator_censorship_ratio=local_params[\"validator_censorship_ratio\"],\n",
    "#         base_block_build_time=local_params[\"base_block_build_time\"],\n",
    "#         base_relay_process_time=local_params[\"base_relay_process_time\"],\n",
    "#         builder_skip_probability=local_params[\"builder_skip_probability\"],\n",
    "#         builder_review_time_per_tx=local_params[\"builder_review_time_per_tx\"],\n",
    "#         relay_review_time_per_tx=local_params[\"relay_review_time_per_tx\"],\n",
    "#         type_1_rejection_prob_builder=local_params[\"type_1_rejection_prob_builder\"],\n",
    "#         type_1_rejection_prob_relay=local_params[\"type_1_rejection_prob_relay\"],\n",
    "#         weak_detection_prob=local_params[\"weak_detection_prob\"],\n",
    "#         proposer_reward_ratio=local_params[\"proposer_reward_ratio\"]\n",
    "#     )\n",
    "\n",
    "#     builder_relay_mapping = agent_setup.construct_builder_relay_mapping(\n",
    "#         builders=builders,\n",
    "#         relays=relays,\n",
    "#         avg_relays_per_builder=local_params[\"avg_relays_per_builder\"],\n",
    "#         censoring_builder_relay_ratio=local_params[\"censoring_builder_relay_ratio\"]\n",
    "#     )\n",
    "\n",
    "#     validator_relay_mapping = agent_setup.construct_validator_relay_mapping(\n",
    "#         validators=validators,\n",
    "#         relays=relays,\n",
    "#         avg_relays_per_validator=local_params[\"avg_relays_per_validator\"],\n",
    "#         censoring_validator_relay_ratio_censoring=1.0,\n",
    "#         censoring_validator_relay_ratio_non_censoring=local_params[\"censoring_validator_relay_ratio_non_censoring\"]\n",
    "#     )\n",
    "\n",
    "#     params_for_simulate = local_params.copy()\n",
    "#     params_for_simulate.pop('num_builders')\n",
    "#     params_for_simulate.pop('num_relays')\n",
    "#     params_for_simulate.pop('num_validators')\n",
    "\n",
    "#     experiment_params = simulate(\n",
    "#         builders=builders,\n",
    "#         relays=relays,\n",
    "#         validators=validators,\n",
    "#         builder_relay_mapping=builder_relay_mapping,\n",
    "#         validator_relay_mapping=validator_relay_mapping,\n",
    "#         **params_for_simulate,\n",
    "#         rng_seed=simulation_rng_seed, \n",
    "#         run_id=run_id,\n",
    "#         stop_time=361.1,\n",
    "#         max_event_count=None,\n",
    "#         experiment_name=f\"builder_review_{builder_time}_relay_review_{relay_time}\",\n",
    "#         result_folder=result_folder\n",
    "#     )\n",
    "\n",
    "#     save_experiment_params(experiment_params, result_folder)\n",
    "\n",
    "#     logger.info(f\"Completed simulation (run_id={run_id}).\")\n",
    "#     # logger.removeHandler(file_handler)\n",
    "#     # file_handler.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_params_list = []\n",
    "\n",
    "# builder_review_times_per_tx = np.linspace(0.000, 0.01, 11)\n",
    "# relay_review_times_per_tx = np.linspace(0.000, 0.01, 11)\n",
    "\n",
    "# for builder_time in builder_review_times_per_tx:\n",
    "#     for relay_time in relay_review_times_per_tx:\n",
    "#         date_str = datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]\n",
    "#         experiment_name = f\"builder_review_{builder_time:.3f}_relay_review_{relay_time:.3f}_{date_str}\"\n",
    "#         result_folder = os.path.join(main_result_folder, experiment_name)\n",
    "#         os.makedirs(result_folder, exist_ok=True)\n",
    "\n",
    "#         for run_id in range(1, 11):\n",
    "#             all_params_list.append((builder_time, relay_time, run_id, result_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Run simulations in parallel using thread pool\n",
    "# \"\"\"\n",
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# import threading\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# num_cores = max(1, os.cpu_count() - 1)\n",
    "# lock = threading.Lock()\n",
    "\n",
    "# progress_bar = tqdm(total=len(all_params_list), desc=\"Total Simulations Progress\", dynamic_ncols=True)\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "#     futures = {executor.submit(run_simulation_parallel, param_tuple): param_tuple for param_tuple in all_params_list}\n",
    "\n",
    "#     for future in as_completed(futures):\n",
    "#         param = futures[future]\n",
    "#         with lock:\n",
    "#             progress_bar.update(1)\n",
    "#             progress_bar.set_postfix_str(f\"builder_review={param[0]:.3f}, relay_review={param[1]:.3f}, run_id={param[2]}\")\n",
    "\n",
    "# progress_bar.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Run simulations in parallel using process pool\n",
    "# \"\"\"\n",
    "# from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "# from tqdm import tqdm\n",
    "# import multiprocessing\n",
    "\n",
    "# num_cores = max(1, multiprocessing.cpu_count() - 1)\n",
    "\n",
    "# progress_bar = tqdm(total=len(all_params_list), desc=\"Total Simulations Progress\", dynamic_ncols=True)\n",
    "\n",
    "# with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "#     futures = {executor.submit(run_simulation_parallel, param_tuple): param_tuple for param_tuple in all_params_list}\n",
    "\n",
    "#     for future in as_completed(futures):\n",
    "#         param = futures[future]\n",
    "#         progress_bar.update(1)\n",
    "#         progress_bar.set_postfix_str(f\"builder_review={param[0]:.3f}, relay_review={param[1]:.3f}, run_id={param[2]}\")\n",
    "\n",
    "# progress_bar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Builder → Relay mappings\n",
    "print(\"Builder → Relay Mapping:\")\n",
    "for b, r_ids in builder_relay_mapping.items():\n",
    "    print(f\"Builder {b} → Relays {r_ids}\")\n",
    "\n",
    "# Print Relay → Builder mappings\n",
    "relay_to_builders = {relay.relay_id: [] for relay in relays}\n",
    "for builder in builders:\n",
    "    for relay in builder.relays:\n",
    "        relay_to_builders[relay.relay_id].append(builder.builder_id)\n",
    "\n",
    "print(\"\\nRelay → Builder Mapping:\")\n",
    "for relay_id, builder_ids in relay_to_builders.items():\n",
    "    print(f\"Relay {relay_id} → Builders {builder_ids}\")\n",
    "\n",
    "# Print Validator → Relay mappings\n",
    "print(\"\\nValidator → Relay Mapping:\")\n",
    "for v, r_ids in validator_relay_mapping.items():\n",
    "    print(f\"Validator {v} → Relays {r_ids}\")\n",
    "\n",
    "# Print Relay → Validator mappings\n",
    "relay_to_validators = {relay.relay_id: [] for relay in relays}\n",
    "for validator in validators:\n",
    "    for relay in validator.connected_relays:\n",
    "        relay_to_validators[relay.relay_id].append(validator.validator_id)\n",
    "\n",
    "print(\"\\nRelay → Validator Mapping:\")\n",
    "for relay_id, validator_ids in relay_to_validators.items():\n",
    "    print(f\"Relay {relay_id} → Validators {validator_ids}\")\n",
    "\n",
    "\n",
    "# Print Builder parameters\n",
    "print(\"\\nBuilders' Parameters:\")\n",
    "for builder in builders:\n",
    "    print(f\"Builder {builder.builder_id}:\\n\"\n",
    "          f\"  - is_censoring: {builder.is_censoring}\\n\"\n",
    "          f\"  - builder_policy: {builder.censorship_policy.builder_policy}\\n\"\n",
    "          f\"  - type_1_rejection_prob_builder: {builder.censorship_policy.type_1_rejection_prob_builder}\\n\"\n",
    "          f\"  - weak_detection_prob: {builder.censorship_policy.weak_detection_prob}\\n\"\n",
    "          f\"  - base_block_build_time: {builder.base_block_build_time}\\n\"\n",
    "          f\"  - builder_review_time_per_tx: {builder.censorship_policy.builder_review_time_per_tx}\\n\"\n",
    "          f\"  - skip_probability: {builder.skip_probability}\\n\"\n",
    "          f\"  - proposer_reward_ratio: {builder.proposer_reward_ratio}\")\n",
    "\n",
    "# Print Relay parameters\n",
    "print(\"\\nRelays' Parameters:\")\n",
    "for relay in relays:\n",
    "    print(f\"Relay {relay.relay_id}:\\n\"\n",
    "          f\"  - is_censoring: {relay.is_censoring}\\n\"\n",
    "          f\"  - relay_policy: {relay.censorship_policy.relay_policy}\\n\"\n",
    "          f\"  - type_1_rejection_prob_relay: {relay.censorship_policy.type_1_rejection_prob_relay}\\n\"\n",
    "          f\"  - base_relay_process_time: {relay.base_relay_process_time}\\n\"\n",
    "          f\"  - relay_review_time_per_tx: {relay.censorship_policy.relay_review_time_per_tx}\")\n",
    "\n",
    "# Print Validator parameters\n",
    "print(\"\\nValidators' Parameters:\")\n",
    "for validator in validators:\n",
    "    print(f\"Validator {validator.validator_id}:\\n\"\n",
    "          f\"  - is_censoring: {validator.is_censoring}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
